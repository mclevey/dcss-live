<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>21&nbsp; Multilevel regression with post-stratification – Doing Computational Social Science&lt;br&gt;[The **Continuous Development** Edition]{.small}</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./22-generalized-linear-models.html" rel="next">
<link href="./20-linear-regression.html" rel="prev">
<link href="./media/logo.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./20-linear-regression.html">Generative Modeling</a></li><li class="breadcrumb-item"><a href="./21-multilevel-regression-with-post-stratification.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multilevel regression with post-stratification</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./media/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Doing Computational Social Science<br><span class="small">The <strong>Continuous Development</strong> Edition</span></a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/UWNETLAB/dcss_supplementary/tree/master/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">👋 Hello!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Learning to Do Computational Social Science</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Research Computing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-getting-started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Started</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-python-101.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-python-102.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python 102</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Obtaining Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-sampling-and-survey-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sampling and survey data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-web-data-apis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Web data (APIs)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-web-data-scraping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Web data (Scraping)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-audio-image-and-document-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Audio, image, and document data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Exploring Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-processing-structured-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Processing Structured Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-exploratory-data-analysis-and-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Exploratory data analysis and visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-association-and-latent-factors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Association and latent factors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-text-as-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Text as Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-text-similarity-and-latent-semantic-space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Text similarity and latent semantic space</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-social-networks-and-relational-thinking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Networks: Relationships as Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-structural-similarity-and-latent-social-space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Structural similarity and latent social space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Prediction and Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-machine-and-statistical-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Machine Learning 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Probability 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-credibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Credibility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Causality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Generative Modeling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bayesian Regression Models with Probabilistic Programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-multilevel-regression-with-post-stratification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multilevel regression with post-stratification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-generalized-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-causal-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Causal analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-latent-structure-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Latent structure in networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-latent-topics-text-lda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent topics in text (LDA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-complex-adaptive-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Agent-based Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./27-developing-agent-based-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Diffusion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning Demystified</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./28-artificial-neural-networks-fnn-rnn-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Neural networks 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./29-processing-natural-language-data-spacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Processing Natural Language Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30-transformers-self-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Transformers, Self-attention architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31-latent-topics-text-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Modelling latent topics (Transformers)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Professional Responsibilities</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32-research-ethics-politics-and-practices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Research Ethics, Politics, and Practices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33-next-steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Next steps</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Acknowledgements</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Changelog</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-centrality-formulas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Centrality Formulas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-courses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Courses and Workshops</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives"><span class="header-section-number">21.1</span> LEARNING OBJECTIVES</a></li>
  <li><a href="#learning-materials" id="toc-learning-materials" class="nav-link" data-scroll-target="#learning-materials"><span class="header-section-number">21.2</span> LEARNING MATERIALS</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">21.3</span> INTRODUCTION</a>
  <ul class="collapse">
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports"><span class="header-section-number">21.3.1</span> Imports</a></li>
  </ul></li>
  <li><a href="#so-whats-a-hierarchical-model" id="toc-so-whats-a-hierarchical-model" class="nav-link" data-scroll-target="#so-whats-a-hierarchical-model"><span class="header-section-number">21.4</span> SO, WHAT’S A HIERARCHICAL MODEL?</a></li>
  <li><a href="#goldilocks-and-the-three-pools" id="toc-goldilocks-and-the-three-pools" class="nav-link" data-scroll-target="#goldilocks-and-the-three-pools"><span class="header-section-number">21.5</span> GOLDILOCKS AND THE THREE POOLS</a>
  <ul class="collapse">
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data"><span class="header-section-number">21.5.1</span> Load Data</a></li>
  <li><a href="#no-pooling-model" id="toc-no-pooling-model" class="nav-link" data-scroll-target="#no-pooling-model"><span class="header-section-number">21.5.2</span> No Pooling Model</a></li>
  <li><a href="#informative-priors-a-spoonful-of-information-makes-the-sampler-calm-down" id="toc-informative-priors-a-spoonful-of-information-makes-the-sampler-calm-down" class="nav-link" data-scroll-target="#informative-priors-a-spoonful-of-information-makes-the-sampler-calm-down"><span class="header-section-number">21.5.3</span> Informative Priors: A Spoonful of Information Makes the Sampler Calm Down</a></li>
  <li><a href="#shrinkage" id="toc-shrinkage" class="nav-link" data-scroll-target="#shrinkage"><span class="header-section-number">21.5.4</span> Shrinkage</a></li>
  <li><a href="#does-the-model-fit-posterior-predictive-plots" id="toc-does-the-model-fit-posterior-predictive-plots" class="nav-link" data-scroll-target="#does-the-model-fit-posterior-predictive-plots"><span class="header-section-number">21.5.5</span> Does the Model Fit? Posterior Predictive Plots</a></li>
  </ul></li>
  <li><a href="#the-best-model-our-data-can-buy" id="toc-the-best-model-our-data-can-buy" class="nav-link" data-scroll-target="#the-best-model-our-data-can-buy"><span class="header-section-number">21.6</span> THE BEST MODEL OUR DATA CAN BUY</a></li>
  <li><a href="#the-fault-in-our-lack-of-stars" id="toc-the-fault-in-our-lack-of-stars" class="nav-link" data-scroll-target="#the-fault-in-our-lack-of-stars"><span class="header-section-number">21.7</span> THE FAULT IN OUR (LACK OF) STARS</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">21.8</span> CONCLUSION</a>
  <ul class="collapse">
  <li><a href="#key-points" id="toc-key-points" class="nav-link" data-scroll-target="#key-points"><span class="header-section-number">21.8.1</span> Key Points</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/UWNETLAB/dcss_supplementary/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./20-linear-regression.html">Generative Modeling</a></li><li class="breadcrumb-item"><a href="./21-multilevel-regression-with-post-stratification.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multilevel regression with post-stratification</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multilevel regression with post-stratification</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="learning-objectives" class="level2" data-number="21.1">
<h2 data-number="21.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">21.1</span> LEARNING OBJECTIVES</h2>
<ul>
<li>Explain what a Hierarchical linear regression model is</li>
<li>Specify a Hierarchical linear regression model using mathematical notation</li>
<li>Specify a Hierarchical linear regression model using PyMC code</li>
<li>Explain what “pooling” is in a Hierarchical linear regression</li>
<li>Differentiate between no pooling, partial pooling, and complete pooling</li>
<li>Use informative priors to fix a problematic sampler</li>
<li>Assess how well Hierarchical models fit the data</li>
<li>Interpret the results of a Hierarchical model</li>
</ul>
</section>
<section id="learning-materials" class="level2" data-number="21.2">
<h2 data-number="21.2" class="anchored" data-anchor-id="learning-materials"><span class="header-section-number">21.2</span> LEARNING MATERIALS</h2>
<p>You can find the online learning materials for this chapter in <code>doing_computational_social_science/Chapter_29</code>. <code>cd</code> into the directory and launch your Jupyter Server.</p>
</section>
<section id="introduction" class="level2" data-number="21.3">
<h2 data-number="21.3" class="anchored" data-anchor-id="introduction"><span class="header-section-number">21.3</span> INTRODUCTION</h2>
<p>Generally speaking, most introductory and intermediate quantitative methods classes for social science students do not teach hierarchical linear regression models except as a special case of ‘default’ linear regression models. This is probably due to the fact that simple linear models are much easier to teach than complex ones, and because of the wise notion that, where possible, we should favour simple models over complex models. And so hierarchical linear models are banished to “advanced” electives that you <em>might</em> get to after years of learning ANOVA-like statistical tests (now with 300+ flavours!). This is all a bit silly given the philosophical gymnastics required of “simple” statistical tests and linear models in the Frequentist tradition. We need a new normal in which our “default” regressions are hierarchical. I’m going to assume that you, like me, were not taught statistics this way and that you may not even know what a hierarchical regression is. Let’s change that.</p>
<section id="imports" class="level3" data-number="21.3.1">
<h3 data-number="21.3.1" class="anchored" data-anchor-id="imports"><span class="header-section-number">21.3.1</span> Imports</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dcss <span class="im">import</span> set_style</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>set_style()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dcss.bayes <span class="im">import</span> plot_2020_no_pool, plot_2020_partial_pool</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="so-whats-a-hierarchical-model" class="level2" data-number="21.4">
<h2 data-number="21.4" class="anchored" data-anchor-id="so-whats-a-hierarchical-model"><span class="header-section-number">21.4</span> SO, WHAT’S A HIERARCHICAL MODEL?</h2>
<p>Linear regression models of any variety can justifiably be called “<strong>hierarchical</strong>” if they use data at different ‘levels’ to estimate parameters and make predictions. I’ll come back to ‘data at different levels’ in a moment, but first I want to acknowledge a very common source of confusion. For no good reason, hierarchical models go by a wide variety of different names, including ‘<strong>random effects</strong>’, ‘<strong>mixed effects</strong>,’ and ‘<strong>multilevel</strong>.’ There are many others as well. The terminology here is hopelessly and inextricably muddled. In some fields, the various terms have specific meanings; in others, they don’t. Sometimes the specific meanings are at odds with one another.</p>
<p>Thankfully none of that really matters for our purposes here. Most of the time I’ll stick with hierarchical, but when I don’t, I mean the same thing. Since you have now been introduced to two different languages for describing your models with precision: code and mathematical notation. A description of your model using either of these two languages is enough to banish any ambiguity about the type of model you’re working with.</p>
<p>What do I mean when I say ‘data at different levels?’ Good question. Anytime I mention something along those lines (including references to ‘<strong>pools</strong>,’ ‘<strong>clusters</strong>,’ etc.), I’m referring to data where observations can be reasonably grouped together because they share some sort of <strong>context</strong>. (You might remember me alluding to this type of model when I introduced relational thinking in Chapter 14, where I compared network analysis to multilevel analysis.) The model we were working with last chapter – the one that investigated if you could predict a Democratic candidate’s margin of victory (or loss) from the amount by which the Democrats outspent (or were outspent by) the Republicans – used clustered data: each of the observations was drawn from one of the United States of America’s 435 Federal Congressional Districts, and each of those districts belonged to one of the 50 States. In this way, the State variable could have acted as a ‘cluster’, in the sense that two Congressional Districts from within the same state are more likely to share similarities with one another than two Congressional Districts chosen at random from the entire dataset.</p>
<p>The real power of a hierarchical model stems from its ability to balance the influence of individual level observations (individual congressional districts) with the influence of whole clusters (each individual state). Bayesian hierarchical models permit this tradeoff between countervailing influences by permitting the slopes (<span class="math inline">\(\beta\)</span>) and intercepts (<span class="math inline">\(\alpha\)</span>) of each cluster to vary from one another, while still forcing all of the slopes and intercepts to be drawn from a simultaneously-estimated prior. This is all getting a little too abstract, so let’s get practical.</p>
</section>
<section id="goldilocks-and-the-three-pools" class="level2" data-number="21.5">
<h2 data-number="21.5" class="anchored" data-anchor-id="goldilocks-and-the-three-pools"><span class="header-section-number">21.5</span> GOLDILOCKS AND THE THREE POOLS</h2>
<p>Whilst working your way through the previous chapter, you might have noticed the word ‘<strong>pool</strong>’ showing up in our model. I didn’t explain it at the time, but the nomenclature was indicative of the modelling strategy we were using. In a regression model, the ‘pooling’ you use determines how the various categorical variables in your model can influence one another. The election data we used had one categorical variable – <code>state</code> – that indicated which of the 50 US States each congressional district belonged to. It might not have seemed so at the time, but our decision to omit the <code>state</code> variable by excluding it from the model entirely was an intentional choice: by preventing our model from accessing the information contained therein, it was forced to treat every congressional district from every state as if they had all come from one giant state (or, equivalently, no state at all). Doing so might have <em>seemed</em> like the ‘default’ option, but the only reason we went that route was for the sake of simplicity.</p>
<p>Now that we’ve seen a full example of developing a simple Bayesian regression model, it’s time to take our categorical data more seriously. The idea here, which I am taking from McElreath’s classic <em>Statistical Rethinking</em>, is that our modelling choices should reflect serious consideration of the options provided to us by the information available to us in our datasets. In this case, we should be asking ourselves: “<em>how should we handle the various U.S. states that appear in this dataset?</em>” Let’s discuss three primary options.</p>
<p><strong>Option 1, Complete Pooling</strong>: All 50 U.S. States are identical.</p>
<p>This is the approach we took in the previous chapter, treating all congressional districts from all states as if there was no meaningful difference between them. This approach is known as ‘Complete Pooling’, because it puts all of the observations into one big ‘pool’ and estimates parameters therefrom (now you know where all those ‘pool’ references come from). This is a simple approach, which is nice, but it’s rarely the best one. It can be overly simplistic, obliterates differences between clusters, and is prone to underfitting. It is highly unlikely, for instance, that increased Democratic election spending will do anything to sway voters in overwhelmingly Republican state of Wyoming. Ditto for Hawaii, where most voters are already committed Democrats. Best to avoid any impulse to artificially impose homogeneity.</p>
<p><strong>Option 2, No Pooling</strong>: All 50 U.S. States are utterly unique.</p>
<p>This approach – called “No Pooling” – would allow each state to have its own intercept (<span class="math inline">\(\alpha\)</span>) and slope (<span class="math inline">\(\beta\)</span>), completely free from any other influences. This would mean that there would be practically no statistical commonalities between them, aside from the (very weak) regularizing influence of our priors. Going this route ensures that nothing our model learns about one state (or all of the states as a whole) can tell us anything about any of the others as individuals. Since the model is now free to create the best fit for each state based on the data available, this approach is very susceptible to overfitting.</p>
<p><strong>Option 3, Partial Pooling</strong>: The U.S. States differ from one another, but there are commonalities about them that we can infer and apply productively.</p>
<p>This approach – which we’ll call ‘Partial Pooling’ – allows states to differ from one another, but places limitations on how they may differ. Rather than giving each state free rein over its own parameters, this approach allows the model to simultaneously learn about each state’s parameters from the data, as well as overall trends for the states in general by way of shared priors.</p>
<p>Logically and statistically, this approach usually makes the most sense: each state differs, but all are political entities within the United States of America, carrying all of the shared norms, values, and traditions incumbent upon belonging to the Union. This is the approach we primarily will use as we dive into hierarchical modelling. Before we do, though, let’s take a brief detour to examine what a ‘No Pooling’ model might look like.</p>
<section id="load-data" class="level3" data-number="21.5.1">
<h3 data-number="21.5.1" class="anchored" data-anchor-id="load-data"><span class="header-section-number">21.5.1</span> Load Data</h3>
<p>Since our exploration of Bayesian hierarchical linear models builds off of the model we developed in the previous chapter, we’re going to re-use the same 2020 House of Representatives Election dataset. We’ll start by loading, standardizing, and previewing the data:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'data/2020_election/2020_districts_combined.csv'</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>spend_std <span class="op">=</span> (df.spend <span class="op">-</span> np.mean(df.spend)) <span class="op">/</span> np.std(df.spend)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>vote_std <span class="op">=</span> (df.vote <span class="op">-</span> np.mean(df.vote)) <span class="op">/</span> np.std(df.vote)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>state_cat <span class="op">=</span> pd.Categorical(df.state)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>state_idx <span class="op">=</span> state_cat.codes</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(state_idx))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>dem_inc <span class="op">=</span> df.dem_inc</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>rep_inc <span class="op">=</span> df.rep_inc</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>pvi_std <span class="op">=</span> (df.pvi <span class="op">-</span> np.mean(df.pvi)) <span class="op">/</span> np.std(df.pvi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Part of our objective in this chapter is to incorporate more of the available data into our model - as you may recall, we only utilized the <code>vote</code> and <code>spend</code> variables in the previous chapter. Now, we’re going to expand our model to incorporate information from the <code>state</code>, <code>dem_inc</code>, <code>rep_inc</code>, and <code>pvi</code> variables. Before proceeding, let’s take a moment to summarize each of the new variables and consider what they represent:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">'dem_inc'</span>, <span class="st">'rep_inc'</span>, <span class="st">'pvi'</span>]].describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The three new variables in our lineup, from left to right in the table above, represent <code>Democratic Incumbent</code>, <code>Republican Incumbent</code>, and <code>Cook Partisan Voting Index</code>, respectively.</p>
<p>The two incumbency variables are straightforward: both are binary categorical variables (whose only possible values are 1 or 0), and they represent which of the parties (if either) has an incumbent in the race. We can’t really combine them in the same way we did with <code>vote</code> and <code>spend</code>, because some districts have no incumbent at all, and it’s not yet clear that the effect of incumbency is the same for Republicans and Democrats alike. We’ll have to keep them separate for now. The ‘Cook Partisan Voting Index’ (<code>pvi</code>) measures how strongly a given congressional district tends to lean towards one of the two major U.S. political parties. It’s based on voting data gathered from the two previous presidential elections, and – for this election – ranges from a minimum of -33 (the deep-red Texas Panhandle), to 43 (the true-blue Bronx).</p>
<p>Without looking at any regression results, I’d expect all three of these variables to play a strong role in our model: collectively, they speak volumes about how each congressional district has voted in the past. In fact, I’d be willing to bet that their collective influence on the model, regardless of its final form, will be stronger than the <code>spend</code> variable’s will be, but that’s fine: the purpose of our model is to tell us what the <code>spend</code> variable’s influence is whilst controlling for things like statewide preferences and historical trends. If, after the control variables are added, our model finds that <code>spend</code> isn’t that important, that’s a perfectly valid result.</p>
<p>Of course, we’re not yet certain how things are going to turn out; there’s a lot of modelling to be done between now and then! As a prelude, let’s take a moment to remind ourselves about the fully-pooled model (i.e., “All 50 states are identical”) we used last chapter:</p>
<p><span class="math display">\[\begin{align}
\text{vote}_i &amp;\sim \text{Normal}(\mu_i, \sigma)&amp; \text{[Likelihood]}  \\
\mu_i &amp;= \alpha + (\beta \cdot \text{spend}_i)  &amp; \text{[Linear Model]} \\
\alpha &amp;\sim \text{Normal}(0, 2)                &amp; \text{[alpha Prior]} \\
\beta  &amp;\sim \text{Normal}(1, 2)                &amp; \text{[beta Prior]} \\
\sigma &amp;\sim \text{Exponential}(2)              &amp; \text{[sigma Prior]} \\
\end{align}\]</span></p>
<p>The above model only uses a single value for <span class="math inline">\(\alpha\)</span> and a single value for <span class="math inline">\(\beta\)</span>, which means that every observation (regardless of which state they come from) must use the same slope and intercept. When we build <em>hierarchical</em> models, we allow the slope and intercept to vary by state. Consequently, we’re going to have to re-build our model such that it is capable of accommodating multiple slopes and multiple intercepts. Rather than use ‘dummy’ variables for each state (as would be the standard Frequentist practice), we’re going to use an unordered categorical ‘<strong>index variable</strong>’. We can write it like so:</p>
<p><span class="math display">\[\begin{align}
\mu_i &amp;= \alpha_{\text{state[i]}} + (\beta_{\text{state[i]}} \cdot \text{spend}_i)
\end{align}\]</span></p>
<p>Translated into plain English, the above line is saying that “The value of <span class="math inline">\(\mu_i\)</span> for a given observation <span class="math inline">\(i\)</span> is equal to the <span class="math inline">\(\alpha\)</span> for that observation’s state plus the product of the <span class="math inline">\(\beta\)</span> for that observation’s state and that observation’s <code>spend</code> value.” This makes it explicit that our model will now accommodate as many different values for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> as there are states in the dataset (48, in our case, since two were dropped).</p>
<p>Now let’s update the rest of the model:</p>
<p><span class="math display">\[\begin{align}
\text{vote}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha_{\text{state[i]}} + (\beta_{\text{state[i]}} \cdot \text{spend}_i)     \\
\alpha_{\text{state[i]}} &amp;\sim \text{Normal}(0, 2)   &amp;  \text{for state[i]} = 0 ... 47            \\
\beta_{\text{state[i]}}  &amp;\sim \text{Normal}(1, 2)   &amp;  \text{for state[i]} = 0 ... 47                \\
\sigma &amp;\sim \text{Exponential}(2)               \\
\end{align}\]</span></p>
<p>Even though each of the 48 <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters are completely separate and will have no influence on one another, <em>they all share the same respective priors</em>. Additionally, the <span class="math inline">\(\text{state[i]}\)</span> that shows up everywhere. I’m particularly fond of the <span class="math inline">\(\text{state[i]}\)</span> nomenclature, because it very closely mirrors how a Python object would behave. What we’re saying in the model definition above is that <span class="math inline">\(\text{state}\)</span> is a mapping that accepts an integer, <span class="math inline">\(\text{i}\)</span> (which can range from 0 to 370), and outputs an integer between 0 and 47. In so doing, it has mapped the observation number (0 - 370) into a state number (0 to 47).</p>
<p>We can replicate this behaviour using variables we’ve already defined:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>district_3_state <span class="op">=</span> state_idx[<span class="dv">3</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(district_3_state)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(state_cat.categories[district_3_state])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Feel free to go check what state the corresponding row in the dataset belongs to; you should see that it’s a perfect match!</p>
<p>Now that we’ve specified our model mathematically, let’s feed it into PyMC:</p>
</section>
<section id="no-pooling-model" class="level3" data-number="21.5.2">
<h3 data-number="21.5.2" class="anchored" data-anchor-id="no-pooling-model"><span class="header-section-number">21.5.2</span> No Pooling Model</h3>
<p>We’ll start by specifying the full model. We won’t go through it step by step, though, as we’re tight on space and we’ve only made a few changes from the model in the previous chapter. Those changes are:</p>
<ul>
<li>We added a <code>shape=n_states</code> parameter to our <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> priors</li>
<li>We added <code>[state_idx]</code> to the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters in the linear model</li>
</ul>
<p>As a result of these changes, the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters are no longer one-dimensional scalars. Instead, they are each vectors of length 48 – one for each of the states in the dataset. Second, during fitting, our model will now seek out the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters that correspond to the <span class="math inline">\(i\)</span>-th district’s state. Here’s what it looks like in action:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> no_pool_model:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pm.Normal(<span class="st">"alpha"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">2</span>, shape<span class="op">=</span>n_states)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span><span class="dv">2</span>, shape<span class="op">=</span>n_states)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, lam<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear Model</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha[state_idx] <span class="op">+</span> beta[state_idx] <span class="op">*</span> spend_std</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    votes <span class="op">=</span> pm.Normal(<span class="st">"votes"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>vote_std)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run Sample Traces</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    trace_no_pool <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If everything works correctly, PyMC should sample without issues. Let’s check the trace plots for the hyperparameters (<a href="#fig-28_01" class="quarto-xref">Figure&nbsp;<span>21.1</span></a>):</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> no_pool_model:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    az.plot_trace(trace_no_pool, [<span class="st">'sigma'</span>], compact<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'figures/28_01.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_01" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_01.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.1: png
</figcaption>
</figure>
</div>
<p>Even though we can’t display all the traces for <code>alpha</code> and <code>beta</code> (since there are 48 of each), a quick glance at our trace for <code>sigma</code> seems to indicate that everything is well and good. This assumption is backed up by the fact that the PyMC sampler didn’t have any grievances to air. Operating under the assumption that our model was well-sampled, let’s proceed with our examination of the results (<a href="#fig-28_02" class="quarto-xref">Figure&nbsp;<span>21.2</span></a>):</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> no_pool_model:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    ppc <span class="op">=</span> pm.sample_posterior_predictive(trace_no_pool, var_names<span class="op">=</span>[<span class="st">'votes'</span>, <span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>plot_2020_no_pool(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    no_pool_model, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    trace_no_pool,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    n_states, </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    state_idx,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    spend_std,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    vote_std,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    ppc,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    state_cat</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/28_02.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_02" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_02.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.2: png
</figcaption>
</figure>
</div>
<p>Each state in the model has a different average regression line, and all of them seem to be doing a good job of fitting the data. While most of the states still show a positive relationship between spending differential and vote differential, not all do: Maine, Alabama, Massachusetts, and New Mexico have completely reversed the trend. Our model has determined that Democrats who outspend Republicans in these states tend to do worse than their colleagues who don’t. According to our model, the only thing the Democrats would have to do to sweep Alabama is stop spending any money there! Though hilarious, this is clearly not a reasonable conclusion for the model to draw. Such is the peril of allowing a model to fit the data as closely as it can.</p>
<p>If you squint and look closely, you might be able to see some small bands around each of the regression lines, covering the interval that we have data for. It might come as little surprise, then, that those little bands are the exact same as the bands we used to surround our regression line from the previous chapter. As a brief refresher: the bands represent the model’s uncertainty about the best-fit regression line (inner band, 94% HDI) and its uncertainty about where the data points themselves lay in relation to the regression line (outer band, 94% HDI; parameterized as ‘<span class="math inline">\(\sigma\)</span>’ in our model’s likelihood, a.k.a. the standard deviation of the normal distribution in our likelihood).</p>
<p>We’re not going to dwell too much on the specifics here: the important takeaway is that our unpooled model has allowed the data for each state to completely determine their own intercept and slope parameters, even when there are only a small number of observations. The only regularizing forces present are the relatively uninformative (and, therefore, weak) priors that we established for this model in the previous chapters (they haven’t changed between now and then). With nothing stopping the model from rushing straight for the best possible fit, we’ve allowed it to descend into the dread valley of overfitting. Damn. Our model does an excellent job at fitting the data we have, but it is, in effect, painting a bullseye around an arrow that had already lodged itself into a wall. In order to curb these tendencies in a principled way, we’re going to turn to the regularizing properties of the hierarchical linear model.</p>
<section id="partially-pooled-model" class="level4" data-number="21.5.2.1">
<h4 data-number="21.5.2.1" class="anchored" data-anchor-id="partially-pooled-model"><span class="header-section-number">21.5.2.1</span> Partially Pooled Model</h4>
<p>Our objective for the hierarchical election model we are developing here is to permit slopes and intercepts to vary between States, but to ensure that each is being drawn from a set of higher-level distributions that encode our model’s knowledge of the States <em>in general</em>. This means that we’re going to have to do away with the numbers (<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>) we’ve been using thus far to specify our <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> priors and replace them with parameters. Let’s do that now, even though the result will be incomplete:</p>
<p><span class="math display">\[\begin{align}
\text{vote}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha_\text{state[i]} + (\beta_\text{state[i]} \cdot \text{spend}_i)     \\
\alpha_\text{state[i]} &amp;\sim \text{Normal}(\alpha_\mu, \alpha_\sigma)   \\
\beta_\text{state[i]}  &amp;\sim \text{Normal}(\beta_\mu, \beta_\sigma)   \\
\sigma &amp;\sim \text{Exponential}(2)               \\
\end{align}\]</span></p>
<p>Okay, great! We’ve now configured our <span class="math inline">\(\alpha\)</span>s and <span class="math inline">\(\beta\)</span>s so that they’ll be drawn from a common, higher-level distribution. This gives us four new variables to play the “what’s that?” game with. Since</p>
<ul>
<li><span class="math inline">\(\alpha_\mu\)</span></li>
<li><span class="math inline">\(\alpha_\sigma\)</span></li>
<li><span class="math inline">\(\beta_\mu\)</span>, and</li>
<li><span class="math inline">\(\beta_\sigma\)</span></li>
</ul>
<p>are all unobserved, they’re going to need priors. You might be thinking to yourself “aren’t <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> <em>already</em> priors? Does this mean we’re going to be giving priors to our priors?”</p>
<p>Yes! Exactly! In order to keep things as conceptually clear as possible, a ‘prior for a prior’ has a special name: ‘<strong>Hyperprior</strong>’. Let’s fill those in now, using similar numerical values as in earlier models. I’ve included line breaks to help clarify which type of prior is which.</p>
<p><span class="math display">\[\begin{align}
\text{vote}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha_\text{state[i]} + (\beta_\text{state[i]} \cdot \text{spend}_i)     \\
\\
\alpha_\text{state[i]} &amp;\sim \text{Normal}(\alpha_\mu, \alpha_\sigma)   \\
\beta_\text{state[i]}  &amp;\sim \text{Normal}(\beta_\mu, \beta_\sigma)   \\
\sigma &amp;\sim \text{Exponential}(2)               \\
\\
\alpha_\mu &amp;\sim \text{Normal}(1, 2) \\
\beta_\mu &amp;\sim \text{Normal}(1, 2) \\
\alpha_\sigma &amp;\sim \text{Exponential}(1) \\
\beta_\sigma &amp;\sim \text{Exponential}(1) \\
\end{align}\]</span></p>
<!-- Alternative Option (Shorter...)

\begin{align}
\text{vote}_i &\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &= \alpha_{\text{state[i]}} + (\beta_{\text{state[i]}} \cdot \text{spend}_i)     \\
\\
\alpha_{\text{state[i]}} &\sim \text{Normal}(\alpha_\mu, \alpha_\sigma)   \\
\beta_{\text{state[i]}}  &\sim \text{Normal}(\beta_\mu, \beta_\sigma)   \\
\sigma &\sim \text{Exponential}(2)               \\
\\
\alpha_\mu &\sim \text{Normal}(1, 2) \\
\beta_\mu &\sim \text{Normal}(1, 2) \\
\alpha_\sigma &\sim \text{Exponential}(1) \\
\beta_\sigma &\sim \text{Exponential}(1) \\
\end{align} 
-->
<p>Now that we have priors, and that our priors have priors (most of them, anyways; good ol’ sigma remains untouched), let’s translate everything into PyMC:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> partial_pool_model:</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hyperpriors</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    alpha_mu <span class="op">=</span> pm.Normal(<span class="st">"alpha_mu"</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    beta_mu <span class="op">=</span> pm.Normal(<span class="st">"beta_mu"</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    alpha_sigma <span class="op">=</span> pm.Exponential(<span class="st">"alpha_sigma"</span>, lam<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    beta_sigma <span class="op">=</span> pm.Exponential(<span class="st">"beta_sigma"</span>, lam<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pm.Normal(<span class="st">"alpha"</span>, mu<span class="op">=</span>alpha_mu, sigma<span class="op">=</span>alpha_sigma, shape<span class="op">=</span>n_states)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, mu<span class="op">=</span>beta_mu, sigma<span class="op">=</span>beta_sigma, shape<span class="op">=</span>n_states)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, lam<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear Model</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha[state_idx] <span class="op">+</span> (beta[state_idx]<span class="op">*</span>spend_std) </span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    votes <span class="op">=</span> pm.Normal(<span class="st">"votes"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>vote_std)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Looking good! Surely, nothing will go wrong when we attempt to fit this model.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> partial_pool_model:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    trace_partial_pool <span class="op">=</span> pm.sample(random_seed<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Something went wrong when we attempted to fit this model.</p>
<section id="the-peril-is-in-the-priors" class="level5" data-number="21.5.2.1.1">
<h5 data-number="21.5.2.1.1" class="anchored" data-anchor-id="the-peril-is-in-the-priors"><span class="header-section-number">21.5.2.1.1</span> The Peril is in the Priors</h5>
<p>Roughly translated, the series of warnings we received can be interpreted as: “The sampling process didn’t go well”. One of the benefits to working with PyMC’s default sampler is that it is <em>very</em> noisy. It will loudly complain whenever anything goes wrong. As annoying as it can be sometimes, you would do well to view this behaviour as a good thing: whenever your sampler is having trouble with your model, it means there’s probably something wrong with your model.</p>
<p>Our largest cause for concern is the number of ‘divergences’ that the sampling process returned. The sampler records a divergence whenever the proverbial marble in the idiomatic skate bowl ends up somewhere that shouldn’t be physically possible: it has ended up buried beneath the terrain, or bounced completely clear of the skate park and is zipping around the city causing chaos.</p>
<p>Let’s examine our trace plot (<a href="#fig-28_03" class="quarto-xref">Figure&nbsp;<span>21.3</span></a>) to see the extent of the damage:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> partial_pool_model:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    az.plot_trace(trace_partial_pool, [<span class="st">'alpha_mu'</span>, <span class="st">'beta_mu'</span>, <span class="st">'alpha_sigma'</span>, <span class="st">'beta_sigma'</span>, <span class="st">'sigma'</span>], compact<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'figures/28_03.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_03" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_03.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.3: png
</figcaption>
</figure>
</div>
<p>This isn’t a completely unmitigated disaster, but the problems are apparent enough that we should go through them in detail. The first thing you might notice here is that our traces don’t meet the criteria we laid out last chapter:</p>
<ol type="1">
<li><strong>The chains are not stationary</strong>: some of the traces in <code>beta_mu</code> and <code>beta_sigma</code> seem to occasionally meander away from the overall mean and then get stuck in a local minima for long periods of time.</li>
<li><strong>The chains are not mixing well</strong>: some of the traces alternate between rapidly zipping from one extreme to another (which is fine) and slowly moving in a single direction for 50 samples at a time or more (which is not fine).</li>
<li><strong>The chains have not converged</strong>: the lower end of <code>beta_sigma</code> has some real issues.</li>
</ol>
<p>Despite everything, overall state of this posterior sampling trace isn’t too bad; if you went ahead with the model as-is, you would probably draw inferences that are pretty close to what you would have gotten from a better-behaved trace… I wouldn’t be in a hurry to submit this to any peer-reviewed journal, though. The bottom line is this: we can do better. To do so, we’re going to have to find a less chaotic way of throwing our marble around this 101-dimensional skate bowl.</p>
</section>
</section>
</section>
<section id="informative-priors-a-spoonful-of-information-makes-the-sampler-calm-down" class="level3" data-number="21.5.3">
<h3 data-number="21.5.3" class="anchored" data-anchor-id="informative-priors-a-spoonful-of-information-makes-the-sampler-calm-down"><span class="header-section-number">21.5.3</span> Informative Priors: A Spoonful of Information Makes the Sampler Calm Down</h3>
<p>There are many ways to tame a rebellious model. We don’t have the space here to cover some of the better ones (reparameterization is the usual go-to), but we wanted to show that informative priors can be used to improve sampling.</p>
<p>In order to keep things simple, we’ve specified each of our spend-vote models thus far using only two different distributions:</p>
<ol type="1">
<li>The Normal Distribution, which we’ve used for parameters that could, theoretically, take on any value on the real number line, and</li>
<li>The Exponential Distribution, which we’ve used as priors for our standard deviation parameters, which must fall somewhere between 0 and positive infinity.</li>
</ol>
<p>Our strategy for calming down our out-of-control model is going to involve tightening up our Normal distributions and swapping out our Exponential distributions for Gamma distributions (another distribution we did not explicitly discuss in Chapter 26, but which you now know how to learn about).</p>
<p>First, “tightening our normals.” All I mean by this is that instead of using the wide, nearly flat priors we’ve been using thus far, we’re going to shrink them down to cover a much smaller part of the real number line. You can see what I mean by looking at the priors for the model specified below.</p>
<p>The switch from an Exponential distribution to a Gamma distribution for our standard deviation parameters needs a bit more explanation. The Gamma distribution is similar to the Exponential in the sense that both can only take on values from 0 to positive infinity (a property we need for our standard deviations), and that they tend to peak early and have long tails. In the interests of avoiding technical jargon, the Gamma distribution will let us ‘scoop’ a bit of the probability density away from 0, which is likely the cause of our woes here.</p>
<p>A quick note: the priors we’re using here are designed to demonstrate how information can be used to combat model degeneracy. As such, they’re a little more strongly informative than you might expect to see in published literature, but not by that much. With these informative priors in place (and no other changes), let’s examine how our model behaves:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> partial_pool_model_regularized:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hyperpriors</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    alpha_mu <span class="op">=</span> pm.Normal(<span class="st">"alpha_mu"</span>, mu<span class="op">=</span><span class="fl">0.1</span>, sigma<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    beta_mu <span class="op">=</span> pm.Normal(<span class="st">"beta_mu"</span>, mu<span class="op">=</span><span class="fl">0.1</span>, sigma<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    alpha_sigma <span class="op">=</span> pm.Gamma(<span class="st">"alpha_sigma"</span>, alpha<span class="op">=</span><span class="dv">4</span>, beta<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    beta_sigma <span class="op">=</span> pm.Gamma(<span class="st">"beta_sigma"</span>, alpha<span class="op">=</span><span class="dv">4</span>, beta<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pm.Normal(<span class="st">"alpha"</span>, mu<span class="op">=</span>alpha_mu, sigma<span class="op">=</span>alpha_sigma, shape<span class="op">=</span>n_states)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, mu<span class="op">=</span>beta_mu, sigma<span class="op">=</span>beta_sigma, shape<span class="op">=</span>n_states)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Gamma(<span class="st">"sigma"</span>, alpha<span class="op">=</span><span class="dv">4</span>, beta<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear Model</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.Deterministic(<span class="st">"mu"</span>, alpha[state_idx] <span class="op">+</span> (beta[state_idx]<span class="op">*</span>spend_std))</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    votes <span class="op">=</span> pm.Normal(<span class="st">"votes"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>vote_std)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run Sample Traces</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    trace_partial_pool_regularized <span class="op">=</span> pm.sample(</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        random_seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Boom! No more divergences! The sampler still had a few grievances to air (at least one of our parameters was sampled very inefficiently), but we should interpret the lack of divergences as permission to manually examine our trace plots (<a href="#fig-28_04" class="quarto-xref">Figure&nbsp;<span>21.4</span></a>):</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> partial_pool_model_regularized:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    az.plot_trace(trace_partial_pool_regularized, [<span class="st">'alpha_mu'</span>, <span class="st">'beta_mu'</span>, <span class="st">'alpha_sigma'</span>, <span class="st">'beta_sigma'</span>, <span class="st">'sigma'</span>], compact<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'figures/28_04.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_04" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_04.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.4: png
</figcaption>
</figure>
</div>
<p>There are a couple of hiccups, and the <code>alpha_sigma</code> traces are verging on non-convergence, but there’s nothing to be too concerned about.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> partial_pool_model_regularized:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    ppc <span class="op">=</span> pm.sample_posterior_predictive(trace_partial_pool_regularized, var_names<span class="op">=</span>[<span class="st">'votes'</span>, <span class="st">'alpha_mu'</span>, <span class="st">'beta_mu'</span>, <span class="st">'alpha_sigma'</span>, <span class="st">'beta_sigma'</span>, <span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>, <span class="st">'mu'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We won’t include the <code>alpha</code> or <code>beta</code> parameters in our ArviZ summary because there are 96 of them in total. No sense reading them all. Instead, we’ll focus on our hyperpriors:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> partial_pool_model_regularized:</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> az.summary(trace_partial_pool_regularized, round_to<span class="op">=</span><span class="dv">2</span>, var_names<span class="op">=</span>[<span class="st">'alpha_mu'</span>, <span class="st">'beta_mu'</span>, <span class="st">'alpha_sigma'</span>, <span class="st">'beta_sigma'</span>, <span class="st">'sigma'</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>summary[[<span class="st">'mean'</span>, <span class="st">'sd'</span>, <span class="st">'r_hat'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It appears that there was a bit of an issue with <code>beta_sigma</code>; our assessment of <code>beta_sigma</code> is backed by the r_hat value of 1.01 (anything noticeably greater than 1.00 indicates something’s amiss). It’s not high enough to be a true cause for concern, but it’s worth pointing out.</p>
<p>Now that we’ve fit our hierarchical model, let’s visualize the results (<a href="#fig-28_05" class="quarto-xref">Figure&nbsp;<span>21.5</span></a>):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plot_2020_partial_pool(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    partial_pool_model_regularized,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    trace_partial_pool_regularized,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    trace_no_pool,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    n_states, </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    state_idx,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    spend_std,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    vote_std,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    ppc,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    state_cat</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/28_05.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_05" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_05.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.5: png
</figcaption>
</figure>
</div>
<p>The above plots should look familiar: they’re very similar to the ones we used to investigate the results from our unpooled model above. All of the elements they share in common are the same, only for our latest model:</p>
<ul>
<li>each of the points represents a single congressional district</li>
<li>the black line represents the regression line from our partially-pooled model, and</li>
<li>the small and large bands around the lines represent the 94% highest density interval of posterior probability for the regressor and the predictions, respectively.</li>
</ul>
<p>There’s one additional element here, though. The grey lines represent the regression lines from the unpooled model; I included them here to facilitate comparison between the partially-pooled and unpooled models.</p>
</section>
<section id="shrinkage" class="level3" data-number="21.5.4">
<h3 data-number="21.5.4" class="anchored" data-anchor-id="shrinkage"><span class="header-section-number">21.5.4</span> Shrinkage</h3>
<p>Let’s dig into these lines a little. First of all, a cursory glance at the previous model’s more outlandish conclusions shows that things have been calmed down considerably. Each of the states with downward-sloping regression lines (predicting worse voting outcomes in districts where Democrats spent more) – such as Alabama, Maine, and New Mexico – have been pulled back from the brink. In the opposite direction, some of the more steeply positive states (such as Kentucky, where the unpooled model predicted that a single standard deviation increase in relative spending for the Democrats would net two standard deviations’ worth of votes) have been reined in.</p>
<p>Another thing you might notice is that each of the single-district states<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> (Wyoming, Vermont, Rhode Island, etc.) have had their regression lines change from perfect fits (where the grey line travels straight through the sole point of data) to more ‘standard’ fits (where the black line misses the point, often by a good margin). That’s not to claim that all of their black lines are identical: they’re not (compare Rhode Island with Montana). Instead, what the model is telling us is that the posterior distribution for each of these individual states isn’t all that much different from the distribution all states are drawing from.</p>
<p>What’s happening here is that all of the states who have had their regression lines ‘calmed down’ by the model are being regularized by the impact of our model’s prior. Unlike a single-level model, however, <em>we didn’t choose this prior: the model learned it from the data</em>!</p>
<p>This is the power of the hierarchical model; it adaptively learns how to straddle the line between underfitting and overfitting, leveraging regularizing probability distributions to calm down overeager predictions. The net effect is that our partially pooled model, at least compared with the unpooled model, has ‘shrunk’ the posterior distribution, causing the model’s predictions to crowd more tightly around a more conservative predictor. This phenomenon is known as ‘<strong>shrinkage</strong>’.</p>
<p>A final parting thought on this topic: you may have noticed that the larger states such as Texas, New York, and California – all of which already had fairly reasonable regression lines – barely changed at all. Each of them were endowed with enough observations that they could largely overwhelm the regularizing influence of the priors.</p>
</section>
<section id="does-the-model-fit-posterior-predictive-plots" class="level3" data-number="21.5.5">
<h3 data-number="21.5.5" class="anchored" data-anchor-id="does-the-model-fit-posterior-predictive-plots"><span class="header-section-number">21.5.5</span> Does the Model Fit? Posterior Predictive Plots</h3>
<p>Adding variables to a model can be an excellent way to explore relationships that simply couldn’t be tackled without some form of multivariate regression. It is unfortunate, then, that adding even a small handful of variables results in a model that the human brain can no longer perceive visually. A regression with just a predictor and an outcome variable is simple: you can capture everything in a two-dimensional scatterplot, with the predictor on the horizontal axis and the outcome on the vertical. A regression with two independent variables (say, a predictor and a control) and one outcome variable is less simple, but doable: you’ll occasionally see them visualized as a 3-dimensional plot with the two independents on the horizontal axes, and with a plane representing the regressor. Anything more than this is practically impossible, as the ‘line’ of best fit becomes a hyperplane that our brains are incapable of visualizing.</p>
<p>In this sad state of affairs, we’re forced to turn to plots that collapse high-dimensional space back down into a 2-dimensional plane that allows us to see the distance between our model’s predictions and the true value of the observations. The resulting plot is called a ‘<strong>posterior predictive plot</strong>’, and is useful for assessing how well our model has fit the data. The main strength of this method is that it scales well into an arbitrarily large number of dimensions: we can picture all of the observations using a single plot. The downside is that we lose some of the nuance that we’d get from other visualizations. Here’s how to make one (results shown in Figure <a href="#fig-28_06" class="quarto-xref">Figure&nbsp;<span>21.6</span></a>):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>mu_hpd <span class="op">=</span> az.hdi(ppc.posterior_predictive[<span class="st">"mu"</span>], <span class="fl">0.89</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>D_sim <span class="op">=</span> ppc.posterior_predictive[<span class="st">"votes"</span>].mean(dim<span class="op">=</span>(<span class="st">"chain"</span>, <span class="st">"draw"</span>)).values</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the error bars using the correct dimension names from mu_hpd</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>yerr_lower <span class="op">=</span> D_sim <span class="op">-</span> mu_hpd.sel(hdi<span class="op">=</span><span class="st">'lower'</span>).mu.values</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>yerr_upper <span class="op">=</span> mu_hpd.sel(hdi<span class="op">=</span><span class="st">'higher'</span>).mu.values <span class="op">-</span> D_sim</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>yerr <span class="op">=</span> np.vstack([yerr_lower, yerr_upper])</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the calculated error bars</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.errorbar(</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    vote_std,</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    D_sim,</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    yerr<span class="op">=</span>yerr,</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">"C0o"</span>,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>vote_std, y<span class="op">=</span>D_sim, s<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'darkgray'</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>min_x, max_x <span class="op">=</span> vote_std.<span class="bu">min</span>(), vote_std.<span class="bu">max</span>()</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>ax.plot([min_x, max_x], [min_x, max_x], <span class="st">"k--"</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Predicted vote differential"</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Observed vote differential"</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/28_06.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_06" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_06.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.6: png
</figcaption>
</figure>
</div>
<p>Each of the points is an observation from our dataset. They’re arranged along the horizontal axis according to their observed (actual) value, and along the vertical axis according to where our model thinks they should be. The vertical lines around each point indicate the range that contains 94% of the posterior probability for that particular observation (remember, in a Bayesian model, <em>everything comes with a healthy dose of uncertainty</em>).</p>
<p>Examining the plot above, we can see that our model does a passable job of retrodicting the voting data using nothing but the ‘state’ and ‘spend’ variables. We can, however, see some real problems at the far-right side of the plot: not only is our model incorrect about almost every district which lays more than ~1.5 standard deviations above the mean, it is <em>confidently</em> incorrect about them. In the next section, we’re going to see if we can do better.</p>
</section>
</section>
<section id="the-best-model-our-data-can-buy" class="level2" data-number="21.6">
<h2 data-number="21.6" class="anchored" data-anchor-id="the-best-model-our-data-can-buy"><span class="header-section-number">21.6</span> THE BEST MODEL OUR DATA CAN BUY</h2>
<p>Now that we have established a Hierarchical baseline and introduced a method for visualizing results from models whose regression ‘lines’ are in higher dimensions (and, thus, aren’t lines any longer, but rather hyperplanes), we can start to add variables in an effort to improve model fit. Unfortunately, we don’t have the room here to report all the proper checks every time we add a variable. Instead, I’ll run you through how to add each of the remaining variables in the dataset and then present the finished model.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> full_hierarchical_model:</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hyperpriors</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    alpha_mu_state <span class="op">=</span> pm.Normal(<span class="st">"alpha_mu_state"</span>, mu<span class="op">=</span><span class="fl">0.1</span>, sigma<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    alpha_sigma_state <span class="op">=</span> pm.Gamma(<span class="st">"alpha_sigma_state"</span>, alpha<span class="op">=</span><span class="dv">4</span>, beta<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    beta_mu_spend <span class="op">=</span> pm.Normal(<span class="st">"beta_mu_spend"</span>, mu<span class="op">=</span><span class="fl">0.1</span>, sigma<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    beta_sigma_spend <span class="op">=</span> pm.Gamma(<span class="st">"beta_sigma_spend"</span>, alpha<span class="op">=</span><span class="dv">4</span>, beta<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors from Hyperpriors</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    alpha_state <span class="op">=</span> pm.Normal(<span class="st">"alpha_state"</span>, mu<span class="op">=</span>alpha_mu_state, sigma<span class="op">=</span>alpha_sigma_state, shape<span class="op">=</span>n_states)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    beta_spend <span class="op">=</span> pm.Normal(<span class="st">"beta_spend"</span>, mu<span class="op">=</span>beta_mu_spend, sigma<span class="op">=</span>beta_sigma_spend, shape<span class="op">=</span>n_states)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    beta_pvi     <span class="op">=</span> pm.Normal(<span class="st">"beta_pvi"</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    beta_rep_inc <span class="op">=</span> pm.Normal(<span class="st">"beta_rep_inc"</span>, mu<span class="op">=-</span><span class="fl">0.5</span>, sigma<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    beta_dem_inc <span class="op">=</span> pm.Normal(<span class="st">"beta_dem_inc"</span>, mu<span class="op">=</span><span class="fl">0.5</span>, sigma<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Gamma(<span class="st">"sigma"</span>, alpha<span class="op">=</span><span class="dv">4</span>, beta<span class="op">=</span><span class="fl">0.10</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear Model</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.Deterministic(<span class="st">"mu"</span>, </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>                         alpha_state[state_idx] <span class="op">+</span> </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>                         beta_spend[state_idx] <span class="op">*</span> spend_std <span class="op">+</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>                         beta_pvi <span class="op">*</span> pvi_std <span class="op">+</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>                         beta_rep_inc <span class="op">*</span> rep_inc <span class="op">+</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>                         beta_dem_inc <span class="op">*</span> dem_inc </span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>                         )</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    votes <span class="op">=</span> pm.Normal(<span class="st">"votes"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>vote_std)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run Sample Traces</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    trace_full_hierarchical_model <span class="op">=</span> pm.sample(</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        target_accept<span class="op">=</span><span class="fl">0.97</span>,</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        random_seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s produce the trace plots for our <code>full_hierarchical_model</code> (<a href="#fig-28_07" class="quarto-xref">Figure&nbsp;<span>21.7</span></a>).</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> full_hierarchical_model:</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    az.plot_trace(trace_full_hierarchical_model, </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                  [</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'alpha_mu_state'</span>, </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'alpha_sigma_state'</span>, </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'beta_mu_spend'</span>, </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'beta_sigma_spend'</span>, </span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'beta_pvi'</span>,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'beta_rep_inc'</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'beta_dem_inc'</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'sigma'</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                  ], compact<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'figures/28_07.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_07" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_07.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.7: png
</figcaption>
</figure>
</div>
<p>There are a few worrying signs here (the <code>alpha_mu_state</code> isn’t sampling as efficiently as we would prefer), but nothing serious enough to call the model into question entirely! Time to take a peek at our model fit (<a href="#fig-28_08" class="quarto-xref">Figure&nbsp;<span>21.8</span></a>):</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> full_hierarchical_model:</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    ppc <span class="op">=</span> pm.sample_posterior_predictive(trace_full_hierarchical_model, var_names<span class="op">=</span>[<span class="st">'votes'</span>, <span class="st">'mu'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>mu_hpd_mean <span class="op">=</span> mu_hpd[<span class="st">'mu'</span>].mean(dim<span class="op">=</span><span class="st">"hdi"</span>).values</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>yerr <span class="op">=</span> np.<span class="bu">abs</span>(ppc.posterior_predictive[<span class="st">"votes"</span>].mean(dim<span class="op">=</span>(<span class="st">"chain"</span>, <span class="st">"draw"</span>)).values <span class="op">-</span> mu_hpd_mean)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>plt.errorbar(</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    vote_std,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    ppc.posterior_predictive[<span class="st">"votes"</span>].mean(dim<span class="op">=</span>(<span class="st">"chain"</span>, <span class="st">"draw"</span>)).values,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    yerr<span class="op">=</span>yerr,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">"C0o"</span>,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>vote_std, y<span class="op">=</span>D_sim, s<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'darkgray'</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>min_x, max_x <span class="op">=</span> vote_std.<span class="bu">min</span>(), vote_std.<span class="bu">max</span>()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>ax.plot([min_x, max_x], [min_x, max_x], <span class="st">"k--"</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Predicted vote differential"</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Observed vote differential"</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>sns.despine()</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/28_06.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_08" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_08.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.8: png
</figcaption>
</figure>
</div>
<p>Much, much better. The addition of two categorical variables (Democratic and Republican incumbency), and one continuous variable (the Cook Partisan Voting Index) has allowed our model’s predictions to fall closer to the observed values across the board.</p>
<p>Even though the above plot does a good job of showing us how well our model fit the data in general, it tells us nothing about the parameters of interest! For that, we’re going to need to turn to a form of plot that can condense large amounts of coefficient information into a relatively small space (we have 51 to examine, after all). It’s called a <strong>forest plot</strong>. Figure <a href="#fig-28_09" class="quarto-xref">Figure&nbsp;<span>21.9</span></a> is the forest plot for our model.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>state_labels <span class="op">=</span> <span class="bu">list</span>(state_cat.categories) </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>additional_labels <span class="op">=</span> [<span class="st">'PVI'</span>, <span class="st">'Democratic Incumbency'</span>, <span class="st">'Republican Incumbency'</span>, <span class="st">'Spending Differential'</span>]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>all_labels <span class="op">=</span> state_labels <span class="op">+</span> additional_labels</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>ax_array <span class="op">=</span> az.plot_forest(trace_full_hierarchical_model,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                          var_names<span class="op">=</span>[<span class="st">'beta_pvi'</span>, <span class="st">'beta_dem_inc'</span>, <span class="st">'beta_rep_inc'</span>, <span class="st">'beta_spend'</span>],</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                          combined<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>                          quartiles<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax_array[<span class="dv">0</span>]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Number of labels: {len(all_labels)}")</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Number of tick locations: {len(ax.get_yticks())}")</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(all_labels) <span class="op">&gt;</span> <span class="bu">len</span>(ax.get_yticks()):</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    all_labels <span class="op">=</span> all_labels[:<span class="bu">len</span>(ax.get_yticks())]</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>ax.set_yticklabels(all_labels)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Coefficients for spending differentials, incumbency, and PVI"</span>)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>sns.despine(left<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-28_09" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-28_09-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/28_09.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-28_09-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.9: png
</figcaption>
</figure>
</div>
<p>After all that, we can finally settle down to the task of interpreting our handiwork.</p>
<p>Looking at the forest plot above, you might be struck by two countervailing trends. The first is that two out of the three variables we added in this latest model have a strong impact on its predictions. It should come as no surprise that the Partisan Voting Index is strongly positively correlated with vote differential, and that Republican incumbency has a predictably negative effect, showing the impact of Republicans’ prior experience in helping them win their races.</p>
<p>The other trend that you might notice is that most of the rest of the model’s claims are relatively tepid. Starting at the top: Democratic incumbency has a positive impact on the Democrats’ vote margins, but it isn’t as significant a boost as was the case for their Republican counterparts – a little under half. Finally, the 94% Highest Density Interval for most of the states’ spending coefficients show only a weak effect, if any at all. Most of the coefficient estimates are above zero, but a good portion of their HDI ranges straddle 0, meaning that our model hasn’t really ruled out the idea that spending has no (or even a negative) effect on Democratic margins of victory. Of all the States under consideration, only in Georgia, Maryland, Michigan, North Carolina, Oregon, and Wisconsin does our model see <em>unambiguous</em> evidence of a positive effect from Democrats outspending Republicans.</p>
<p>One interpretation of these results is that Democratic spending advantages don’t often translate into vote advantages. An equally valid interpretation, and one which takes into account the specific historical context, is that Democrats did a good job of funneling their resources towards close races in states whose districts were ripe for a Democratic breakthrough. They didn’t succeed in all cases, but were able to translate their funding advantage in North Carolina and Georgia into a total of three seats flipped in their favour (the Democrats neither gained nor lost seats in any of the other states mentioned above).</p>
<p>Is this enough? Should we, at this point, be satisfied?</p>
<p>No.</p>
<p>Anytime we create a model with more than two variables, it is incumbent upon us to think through the causal implications of what we have done. To once again paraphrase Richard McElreath, whose <em>Statistical Rethinking</em> has had a major influence on our discussion of Bayesian regression, a regression model is implicitly asking a set of questions about each of its variables simultaneously: that question almost always boils down to something like “<em>how much predictive information does this variable contain, once the effect of all the other variables is known?</em>” Since we’re interested in the influence of spending differentials on vote differentials across different states, we’re implicitly using our regression model to ask: “<em>what is the value of knowing the effect of the spending differential once the effects from incumbency and the partisan voting index are already known?</em>”</p>
<p>Here’s a plausible explanation for what’s happening here. The negative effect that we’re seeing in Texas might be indicative of a concerted Democratic push to try and flip historically Republican-leaning districts. If you paid attention to the 2020 American election, you might know that Democrats generally underperformed in the 2020 House races, and as such, our model may be picking up on an effect wherein Democrats funneled cash into break-even or Republican-leaning districts, only to be rebuffed. To do this, they would have presumably had to move cash away from safer Democratic-leaning districts in metro Houston and Austin. Under such circumstances, it might be entirely plausible that, <em>once we control for all the other variables in the model</em>, Democrats were more likely to lose ridings they overspent on, and win those they underspent on.</p>
<p>Another problem is that our model is helpless to tell us if the presumed causal relationship underpinning the whole shebang (namely, that money helps win elections) is justifiable. It’d be just as easy to claim that our predictor (money spent) and outcome (votes received) variables share no direct causal link, and instead share ‘political popularity’ as a common cause. The logic there being that popular candidates might be more likely to attract donations AND votes. Modelling can’t help us here. The best regression model in the world, be it Bayesian or Frequentist, wouldn’t be able to help you determine if there’s any validity to your assumptions of causality. If you’re interested, computational social science is in the midst of a causal inference renaissance, and thanks primarily to people like the brilliant computer scientist Judea Pearl, that renaissance is Bayesian. Unfortunately, this is another area of computational social science that we simply don’t have the space to cover in this book.</p>
<p>There is, in fact, a lot more we <em>could</em> get into here, but our hands are tied by space constraints and by the fact that this book is not a Bayesian regression textbook. Hopefully you’ve seen that it is possible, and even fun, to build an interesting, functional, and sophisticated statistical model from scratch. Its imperfections represent room for improvement, not something to be feared or ashamed of.</p>
</section>
<section id="the-fault-in-our-lack-of-stars" class="level2" data-number="21.7">
<h2 data-number="21.7" class="anchored" data-anchor-id="the-fault-in-our-lack-of-stars"><span class="header-section-number">21.7</span> THE FAULT IN OUR (LACK OF) STARS</h2>
<p>Somewhere, someone in the world is saying something like “Hold up, John. This is a chapter on regression analysis! Where are the hypothesis tests!? Where are the little stars that tell me if I can publish my findings or not?”</p>
<p>As these chapters have probably made abundantly clear, that’s not what we’re doing here. The Bayesian statistical paradigm is capable of comparing hypotheses in the way Frequentists think of such things, but are generally loath to do so. This is because we already have access to a very broad <em>range</em> of hypotheses defined by a posterior probability distribution, and that distribution already contains all of the information we can possibly derive from our model for a given set of data. Anything else we do – plotting, calculating HDI, hypothesis testing – is simply a summarization of that posterior distribution.</p>
<p>If you feel like comparing hypotheses in the style of a Frequentist, go for it. All of the Bayesian regression models we fit today contain infinite hypotheses (in multiple dimensions!) and the probability of any individual from among them (say, <span class="math inline">\(\beta = 3\)</span>) being ‘true’ (whatever that means) is 0. We’ve already covered why that’s the case.</p>
<p>You could compare ranges of hypotheses against a ‘null’ of sorts, but the Bayesian paradigm ensures that a simple posterior plot is all that is needed to quickly ascertain whether or not most of the posterior probability for any given parameter is credibly distant from 0, which is all null-hypothesis significance testing does really does anyhow.</p>
<p>Instead of using null-hypothesis significance testing, consider treating each model as its own ‘hypothesis’ of sorts. Gelman and Shalizi <span class="citation" data-cites="gelman2013philosophy">(<a href="references.html#ref-gelman2013philosophy" role="doc-biblioref">2013</a>)</span> advocate a paradigm wherein whole models are judged by how well they fit data (both in-sample and out-of-sample). Accepted models are used until their flaws become too egregious to ignore, at which point new, better models are developed using insights from the failings of the previous one. It’s a different way of doing science than you might be used to, but it’s worth knowing about: the winds of change are blowing decisively away from the traditional null hypothesis testing paradigm.</p>
<blockquote class="blockquote">
<p><strong>Further Reading</strong></p>
<p>As I mentioned in several previous chapters, there are a number of outstanding resources that you can now turn to to continue your journey into Bayesian regression analysis. I especially recommend <span class="citation" data-cites="mcelreath2020statistical">McElreath (<a href="references.html#ref-mcelreath2020statistical" role="doc-biblioref">2020</a>)</span>, <span class="citation" data-cites="lambert2018student">Lambert (<a href="references.html#ref-lambert2018student" role="doc-biblioref">2018</a>)</span>, <span class="citation" data-cites="kruschke2014doing">Kruschke (<a href="references.html#ref-kruschke2014doing" role="doc-biblioref">2014</a>)</span>, and <span class="citation" data-cites="martin2018bayesian">Martin (<a href="references.html#ref-martin2018bayesian" role="doc-biblioref">2018</a>)</span>. Finally, <span class="citation" data-cites="lynch2019bayesian">Lynch and Bartlett (<a href="references.html#ref-lynch2019bayesian" role="doc-biblioref">2019</a>)</span> offer a literature review of the use of Bayesian statistics in sociology.</p>
</blockquote>
</section>
<section id="conclusion" class="level2" data-number="21.8">
<h2 data-number="21.8" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">21.8</span> CONCLUSION</h2>
<section id="key-points" class="level3" data-number="21.8.1">
<h3 data-number="21.8.1" class="anchored" data-anchor-id="key-points"><span class="header-section-number">21.8.1</span> Key Points</h3>
<ul>
<li>Any regression dataset that features at least one clustering variable should be modelled, by default, using partially pooled hierarchical regression; any simpler models should only be used if justified</li>
<li>Wide, uninformative priors can cause a large number of divergences during sampling using an HMC sampler; using tighter, more informative priors can help ameliorate this.</li>
<li>Higher-dimensional regression models (those with more than two variables) are difficult (if not impossible) to fully visualize – we can instead turn to specialized visualizations to assess model fit (via retrodiction) and model parameters (via forest plots)</li>
<li>The First Rule of Bayes Club is that we don’t do p-values, stars, or null hypothesis significance testing (exceptions apply)</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-gelman2013philosophy" class="csl-entry" role="listitem">
Gelman, Andrew, and Cosma Rohilla Shalizi. 2013. <span>“Philosophy and the Practice of Bayesian Statistics.”</span> <em>British Journal of Mathematical and Statistical Psychology</em> 66 (1): 8–38.
</div>
<div id="ref-kruschke2014doing" class="csl-entry" role="listitem">
Kruschke, John. 2014. <span>“Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan.”</span>
</div>
<div id="ref-lambert2018student" class="csl-entry" role="listitem">
Lambert, Ben. 2018. <em>A Student’s Guide to Bayesian Statistics</em>. Sage.
</div>
<div id="ref-lynch2019bayesian" class="csl-entry" role="listitem">
Lynch, Scott, and Bryce Bartlett. 2019. <span>“Bayesian Statistics in Sociology: Past, Present, and Future.”</span> <em>Annual Review of Sociology</em> 45: 47–68.
</div>
<div id="ref-martin2018bayesian" class="csl-entry" role="listitem">
Martin, Osvaldo. 2018. <em>Bayesian Analysis with Python: Introduction to Statistical Modeling and Probabilistic Programming Using Pymc and ArviZ</em>. Packt Publishing Ltd.
</div>
<div id="ref-mcelreath2020statistical" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical Rethinking: A Bayesian Course with Examples in r and Stan</em>. CRC press.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note that many of these states aren’t actually single-district states, but rather only have one valid district in the dataset because of the filtering we had to do<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./20-linear-regression.html" class="pagination-link" aria-label="Bayesian Regression Models with Probabilistic Programming">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bayesian Regression Models with Probabilistic Programming</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./22-generalized-linear-models.html" class="pagination-link" aria-label="Generalized Linear Models">
        <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/UWNETLAB/dcss_supplementary/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>