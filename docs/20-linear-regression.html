<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>20&nbsp; Bayesian Regression Models with Probabilistic Programming – Doing Computational Social Science&lt;br&gt;[The **Continuous Development** Edition]{.small}</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./21-multilevel-regression-with-post-stratification.html" rel="next">
<link href="./19-causality.html" rel="prev">
<link href="./figures/logo.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./20-linear-regression.html">Generative Modeling</a></li><li class="breadcrumb-item"><a href="./20-linear-regression.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bayesian Regression Models with Probabilistic Programming</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./figures/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Doing Computational Social Science<br><span class="small">The <strong>Continuous Development</strong> Edition</span></a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/UWNETLAB/dcss_supplementary/tree/master/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">👋 Hello!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Learning to Do Computational Social Science</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Research Computing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-getting-started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Started</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-python-101.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Python 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-python-102.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python 102</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Obtaining Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-sampling-and-survey-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sampling and survey data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-web-data-apis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Web data (APIs)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-web-data-scraping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Web data (Scraping)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-audio-image-and-document-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Audio, image, and document data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Exploring Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-processing-structured-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Processing Structured Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-exploratory-data-analysis-and-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Exploratory data analysis and visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-association-and-latent-factors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Association and latent factors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-text-as-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Text as Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-text-similarity-and-latent-semantic-space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Text similarity and latent semantic space</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-social-networks-and-relational-thinking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Networks: Relationships as Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-structural-similarity-and-latent-social-space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Structural similarity and latent social space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Prediction and Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-machine-and-statistical-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Machine Learning 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Probability 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-credibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Credibility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Causality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Generative Modeling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-linear-regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bayesian Regression Models with Probabilistic Programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-multilevel-regression-with-post-stratification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multilevel regression with post-stratification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22-generalized-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23-causal-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Causal analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24-latent-structure-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Latent structure in networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25-latent-topics-text-lda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent topics in text (LDA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26-complex-adaptive-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Agent-based Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./27-developing-agent-based-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Diffusion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning Demystified</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./28-artificial-neural-networks-fnn-rnn-cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Neural networks 101</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./29-processing-natural-language-data-spacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Processing Natural Language Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30-transformers-self-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Transformers, Self-attention architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31-latent-topics-text-transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Modelling latent topics (Transformers)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Professional Responsibilities</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32-research-ethics-politics-and-practices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Research Ethics, Politics, and Practices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33-next-steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Next steps</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Acknowledgements</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Changelog</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-centrality-formulas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Centrality Formulas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-courses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Courses and Workshops</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives"><span class="header-section-number">20.1</span> LEARNING OBJECTIVES</a></li>
  <li><a href="#learning-materials" id="toc-learning-materials" class="nav-link" data-scroll-target="#learning-materials"><span class="header-section-number">20.2</span> LEARNING MATERIALS</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">20.3</span> INTRODUCTION</a>
  <ul class="collapse">
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports"><span class="header-section-number">20.3.1</span> Imports</a></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data"><span class="header-section-number">20.3.2</span> Data</a></li>
  <li><a href="#checking-and-cleaning-the-data" id="toc-checking-and-cleaning-the-data" class="nav-link" data-scroll-target="#checking-and-cleaning-the-data"><span class="header-section-number">20.3.3</span> Checking and Cleaning the Data</a></li>
  </ul></li>
  <li><a href="#developing-our-bayesian-model" id="toc-developing-our-bayesian-model" class="nav-link" data-scroll-target="#developing-our-bayesian-model"><span class="header-section-number">20.4</span> DEVELOPING OUR BAYESIAN MODEL</a>
  <ul class="collapse">
  <li><a href="#making-the-model-with-pymc" id="toc-making-the-model-with-pymc" class="nav-link" data-scroll-target="#making-the-model-with-pymc"><span class="header-section-number">20.4.1</span> Making the Model with PyMC</a></li>
  <li><a href="#prior-predictive-check" id="toc-prior-predictive-check" class="nav-link" data-scroll-target="#prior-predictive-check"><span class="header-section-number">20.4.2</span> Prior Predictive Check</a></li>
  <li><a href="#running-our-model" id="toc-running-our-model" class="nav-link" data-scroll-target="#running-our-model"><span class="header-section-number">20.4.3</span> Running Our Model</a></li>
  <li><a href="#checking-the-traceplot" id="toc-checking-the-traceplot" class="nav-link" data-scroll-target="#checking-the-traceplot"><span class="header-section-number">20.4.4</span> Checking the Traceplot</a></li>
  <li><a href="#establishing-credible-intervals" id="toc-establishing-credible-intervals" class="nav-link" data-scroll-target="#establishing-credible-intervals"><span class="header-section-number">20.4.5</span> Establishing Credible Intervals</a></li>
  <li><a href="#posterior-predictive-checks" id="toc-posterior-predictive-checks" class="nav-link" data-scroll-target="#posterior-predictive-checks"><span class="header-section-number">20.4.6</span> Posterior Predictive Checks</a></li>
  <li><a href="#plotting-uncertainty" id="toc-plotting-uncertainty" class="nav-link" data-scroll-target="#plotting-uncertainty"><span class="header-section-number">20.4.7</span> Plotting Uncertainty</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">20.5</span> CONCLUSION</a>
  <ul class="collapse">
  <li><a href="#key-points" id="toc-key-points" class="nav-link" data-scroll-target="#key-points"><span class="header-section-number">20.5.1</span> Key Points</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/UWNETLAB/dcss_supplementary/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./20-linear-regression.html">Generative Modeling</a></li><li class="breadcrumb-item"><a href="./20-linear-regression.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bayesian Regression Models with Probabilistic Programming</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bayesian Regression Models with Probabilistic Programming</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="learning-objectives" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">20.1</span> LEARNING OBJECTIVES</h2>
<ul>
<li>Specify a Bayesian linear regression model with PyMC</li>
<li>Understand the logic of using Python’s context management to develop models with PyMC</li>
<li>Use PyMC to conduct a prior predictive check to ensure that our model is not overly influenced by our priors</li>
<li>Read a traceplot to assess the quality of a stochastic sampler</li>
<li>Assess and interpret models by
<ul>
<li>Constructing and interpreting credible intervals using the Highest Density Interval method</li>
<li>Conducting Posterior Predictive Checks</li>
<li>Plotting uncertainty</li>
</ul></li>
</ul>
</section>
<section id="learning-materials" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="learning-materials"><span class="header-section-number">20.2</span> LEARNING MATERIALS</h2>
<p>You can find the online learning materials for this chapter in <code>doing_computational_social_science/Chapter_28</code>. <code>cd</code> into the directory and launch your Jupyter Server.</p>
</section>
<section id="introduction" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="introduction"><span class="header-section-number">20.3</span> INTRODUCTION</h2>
<p>In this chapter, we’ll actually develop some Bayesian regression models. We will slowly develop a simple linear model, explaining the ins and outs of the process using a package for probabilistic programming called PyMC. Then we’ll criticize the model we’ve built and use those critiques to build a much better model in the next chapter.</p>
<p>Our example here, and in the next chapter, will be the influence of money on voting outcomes by state in the 2020 American General Election. Given that we would like data that is regionally representative and as numerous as possible, we’re going to focus on the electoral contests that took place across America’s 435 congressional districts.</p>
<p>It’s almost a truism to state that money wins elections. In light of this fact, one of the most critical decisions a political party can make is where and how to allocate their funds. It’s far from an easy problem to solve: every dollar spent on a race where the result is a foregone conclusion represents a dollar that might have helped shift the result in a more tightly-contested district. In the US, both the Democratic and Republican parties are perpetually attempting to outdo each other by allocating their limited resources more efficiently, but their task is an asymmetric one: Republicans might, for instance, get better returns (measured in votes) on their investment in Alabama than Democrats would in the same state for the same amount. Of course, given that Alabama swings so heavily Republican, it might be a mistake for any party to invest funds there, given that the races in most of Alabama’s districts were probably over before they began. Let’s see what we can learn.</p>
<section id="imports" class="level3" data-number="20.3.1">
<h3 data-number="20.3.1" class="anchored" data-anchor-id="imports"><span class="header-section-number">20.3.1</span> Imports</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dcss.bayes <span class="im">import</span> plot_2020_election_diff, plot_2020_election_fit</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dcss <span class="im">import</span> set_style, download_dataset</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>set_style()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="data" class="level3" data-number="20.3.2">
<h3 data-number="20.3.2" class="anchored" data-anchor-id="data"><span class="header-section-number">20.3.2</span> Data</h3>
<p>The data we will use for this chapter is stored in a CSV called <code>2020_election/2020_districts_combined.csv</code>. Rather than take you through the entire process of cleaning and pre-processing the data, we’ve done it for you this time; it’s ready to go! It’s worth noting, however, that the cleaning and pre-processing steps we’ve taken for this data (and the models we’re going to fit in this chapter) are <em>very</em> similar to those that we’ve taken in previous chapters.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>us_election_2020_data_url <span class="op">=</span> <span class="st">"https://www.dropbox.com/scl/fo/gcotab57xtv9a0ga5vums/ANB2gm71cIXW1NcLwA5ezXY?rlkey=nai1uun6mkl10a66ekzs692ux&amp;st=rmbsufjx&amp;dl=0"</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>download_dataset(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    us_election_2020_data_url, <span class="st">'data/2020_election/'</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/2020_election/2020_districts_combined.csv'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this chapter, we’re only going to be utilizing a small subset of the available variables: going forward, I’m going to restrict my discussion to only those that are pertinent to this chapter (the rest will come into play in the subsequent chapter).</p>
</section>
<section id="checking-and-cleaning-the-data" class="level3" data-number="20.3.3">
<h3 data-number="20.3.3" class="anchored" data-anchor-id="checking-and-cleaning-the-data"><span class="header-section-number">20.3.3</span> Checking and Cleaning the Data</h3>
<p>We’ll start by summarizing the variables we intend to use. Doing so helps us get a sense of what those variables look like, where on the number line they lie, and how they might best be modelled. We can do this with using Panda’s <code>.describe()</code> method.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>pd.options.display.float_format <span class="op">=</span> <span class="st">"</span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">'vote'</span>, <span class="st">'spend'</span>, <span class="st">'districts'</span>]].describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>state</code> and <code>districts</code> variables are straightforward: they represent the state and numerical identifier associated with the congressional district in question. The <code>vote</code> and <code>spend</code> columns are a little more involved. For the past 29 years, American federal elections have been an almost completely two-party affair. Almost all viable candidates at almost every level of government belong to either the Democratic or Republican parties. There are some notable exceptions (such as the technically independent senators Bernie Sanders and Angus King), but almost all politically viable independent politicians in the US are Democrats in all but name (they often even receive the official endorsement of the Democratic party, and are not opposed by any member). Given the ubiquity of this political duopoly, we can simplify our data by focusing solely on the differential in votes and spending between the two major parties.</p>
<p>We’ve decided to treat Republicans as our ‘negative’ case and the Democrats as our ‘positive’ case. Casting the two in diametric opposition allows the <code>vote</code> and <code>spend</code> variables to represent the <em>differential</em> between the two parties: when <code>vote</code> is positive, it means the Democrats received more votes than the Republicans. A negative <code>vote</code> value means the Republicans received more votes than the Democrats. Ditto for <code>spend</code>.</p>
<p>Although this helps us simplify our model immensely, it also comes at a cost: we can only include districts where both Democrats and Republicans <em>officially</em> ran, spent campaign funds, and received votes. This limitation has reduced our data from 435 districts to 371; a steep cost, but not an altogether unwarranted one. More advanced models could incorporate and model the dropped data, but we’re keeping it simple.</p>
<p>Now that the data is loaded, let’s create a scatterplot so we can see how it is distributed (<a href="#fig-26_01" class="quarto-xref">Figure&nbsp;<span>20.1</span></a>).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plot_2020_election_diff(df)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/27_01.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_01" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/27_01.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.1: png
</figcaption>
</figure>
</div>
<p>In the above scatterplot, each point represents a single congressional district in one of the 50 states. The x-axis represents the Democrats’ ‘spending differential’, which is just the amount of money the Democrats spent in a congressional race minus the amount the Republicans spent in the same. The y-axis, ‘vote differential’, is similar: it represents the amount of votes the Democrats received minus the amount the Republicans received.</p>
<p>I’ve broken the plot into four quadrants and labelled them. The upper-left quadrant represents the best-case scenario for the Democrats: districts here were won by Democratic candidates despite the fact that the Republicans spent more money on the race. The lower-right is the inverse; it represents the worst-case scenario for the Democrats, wherein they outspent the Republicans yet still lost. You might notice that comparatively few districts fall into these two quadrants: this might imply that both parties are fairly adept at avoiding overspending in districts where they’re unsure of victory.</p>
<p>The final two quadrants, upper-right and lower-left, contain the districts where the winning party spent more money than their opponents did (which, for the most part, is what we’d expect). Now let’s prepare the model for inclusion in our model.</p>
<section id="standardize-data-process-categoricals" class="level4" data-number="20.3.3.1">
<h4 data-number="20.3.3.1" class="anchored" data-anchor-id="standardize-data-process-categoricals"><span class="header-section-number">20.3.3.1</span> Standardize Data, Process Categoricals</h4>
<p>Generally speaking, it’s a good idea to standardize any non-categorical data you plan to use in a modelling context. We do this by first shifting the numerical value so that its mean is 0. Then, we divide each observation by the standard deviation of the data, which converts the variable into a value whose units are ‘standard deviations’, or z-scores. We’re also going to tackle our non-numerical categorical variable, <code>state</code>, which is currently a list of strings (the <code>districts</code> variable is also categorical, but it’s already numerical and is thus good-to-go as-is). We’re going to use Pandas to convert <code>state</code> into an explicitly categorical object, extract numerical codes from it, and then use those codes to determine how many different states we’re working with (remember, some may have been dropped when we cleansed our data of ~60 districts). The code cell below accomplishes all this; there are more efficient ways to accomplish our task, and we’ve even covered some of them elsewhere in the book. Nevertheless, we’re going to do them manually here to help give you a better sense of what’s going on.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>spend_std <span class="op">=</span> (df.spend <span class="op">-</span> np.mean(df.spend)) <span class="op">/</span> np.std(df.spend)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>vote_std <span class="op">=</span> (df.vote <span class="op">-</span> np.mean(df.vote))<span class="op">/</span> np.std(df.vote)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>state_cat <span class="op">=</span> pd.Categorical(df.state)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>state_idx <span class="op">=</span> state_cat.codes</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(state_idx))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="developing-our-bayesian-model" class="level2" data-number="20.4">
<h2 data-number="20.4" class="anchored" data-anchor-id="developing-our-bayesian-model"><span class="header-section-number">20.4</span> DEVELOPING OUR BAYESIAN MODEL</h2>
<p>Using the modelling language we established in the previous chapter, let’s create a model that uses spending differential to predict vote differential in congressional districts:</p>
<p><span class="math display">\[\begin{align}
\text{vote}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + (\beta \cdot \text{spend}_i)  
\end{align}\]</span></p>
<p>Based on the hypothetical model we developed last chapter, this format should look familiar: the top line is our likelihood, and the linear model on the second line determines where the mean of the likelihood function falls. Now that we have our likelihood and linear model specified, we can play the “What’s That?” game, which will see us through to the creation of a fully-specified model. Let’s look at our model definition again; we’ll start with the data, which are the variables whose values we have observations of. They are:</p>
<ol type="1">
<li><span class="math inline">\(\text{vote}_i\)</span></li>
<li><span class="math inline">\(\text{spend}_i\)</span></li>
</ol>
<p>We have real, actual numerical values for both of the above, so we don’t need to do any guessing about them. Next, let’s turn our gaze to the statistics - the variables whose values are (at least in part) derived from other variables:</p>
<ol type="1">
<li><span class="math inline">\(\mu_i\)</span> - mean parameter for likelihood function</li>
<li><span class="math inline">\(\alpha\)</span> - the intercept</li>
<li><span class="math inline">\(\beta\)</span> - coefficient for <code>spend</code></li>
<li><span class="math inline">\(\sigma\)</span> - standard deviation parameter for likelihood function</li>
</ol>
<p>Since we don’t have any strong reasons to think that any of those variables should take on any particular values, we can use <em>uninformative priors</em> for each. We have a large amount of data to work with, so as long as our priors are not unduly mis-specified, they will likely be overwhelmed by the weight of evidence and have no noticeable impact on our posterior distributions. Here’s what I’ve elected to use (feel free to play around with different priors at your leisure). The text on the right (Likelihood, Linear Model, etc.) is not necessary, but it’s a nice reminder of what each line in the model represents.</p>
<p><span class="math display">\[\begin{align}
\text{vote}_i &amp;\sim \text{Normal}(\mu_i, \sigma)&amp; \text{[Likelihood]}  \\
\mu_i &amp;= \alpha + (\beta \cdot \text{spend}_i)  &amp; \text{[Linear Model]} \\
\alpha &amp;\sim \text{Normal}(0, 2)                &amp; \text{[alpha Prior]} \\
\beta  &amp;\sim \text{Normal}(1, 2)                &amp; \text{[beta Prior]} \\
\sigma &amp;\sim \text{Exponential}(2)              &amp; \text{[sigma Prior]} \\
\end{align}\]</span></p>
<section id="making-the-model-with-pymc" class="level3" data-number="20.4.1">
<h3 data-number="20.4.1" class="anchored" data-anchor-id="making-the-model-with-pymc"><span class="header-section-number">20.4.1</span> Making the Model with PyMC</h3>
<p>Since we’ve already discussed how and why to use stochastic samples to approximate the posterior distribution in a Bayesian model, we’ll go straight into using stochastic samplers using a package called PyMC. PyMC is designed to facilitate the specification, fitting, and simulation of Bayesian models, and it includes state-of-the-art stochastic samplers. While far more sophisticated than anything we’ve described in this book thus far, PyMC is conceptually similar to – and based upon – the Markov Chain and related techniques covered in the previous chapter.</p>
<p>PyMC is expansive and constantly evolving – any attempt to capture even a modest percentage of its contents would be futile. As with other packages discussed in this book, you will likely use a very small portion of it extensively, and the rest much more rarely. I encourage you to avail yourselves of PyMC’s extensive <a href="https://www.pymc.io/projects/docs/en/latest/index.html">documentation and helpful tutorials</a>. For now, we will focus on what you need to build your own Bayesian regression from scratch.</p>
<p>Before we actually make the model, we have to introduce a bit of Python programming knowledge that we’ve <em>used</em> before but have not actually explained: context management.</p>
<blockquote class="blockquote">
<p><strong>Further Reading</strong></p>
<p><span class="citation" data-cites="salvatier2016probabilistic">Salvatier, Wiecki, and Fonnesbeck (<a href="references.html#ref-salvatier2016probabilistic" role="doc-biblioref">2016</a>)</span> provide a detailed introduction to PyMC, and <span class="citation" data-cites="martin2018bayesian">Martin (<a href="references.html#ref-martin2018bayesian" role="doc-biblioref">2018</a>)</span> provides an excellent in-depth introduction to statistical modelling and probabilistic programming with PyMC. If you want to go beyond the Bayesian methods we discuss in this book, I especially recommend working though <span class="citation" data-cites="martin2018bayesian">Martin (<a href="references.html#ref-martin2018bayesian" role="doc-biblioref">2018</a>)</span>.</p>
</blockquote>
<section id="context-management-for-modelling-with-pymc" class="level4" data-number="20.4.1.1">
<h4 data-number="20.4.1.1" class="anchored" data-anchor-id="context-management-for-modelling-with-pymc"><span class="header-section-number">20.4.1.1</span> Context Management for Modelling with PyMC</h4>
<p>Although the PyMC package has a wide variety of use cases, we’ll exclusively use it for modelling. PyMC uses an unusual (though convenient) convention to simplify the necessary syntax for modelling. To understand it, we first have to briefly cover what a ‘Context’ is in Python.</p>
<p>Python contexts are immediately recognizable by their use of the <code>with</code> statement, and are usually employed to manage system resources that are in limited supply. That’s why you’ll frequently see them used with I/O operations, where files are being read from or written to disk. Rather than leaving those files open and available for further editing, the <code>with</code> block ensures that the files are opened and closed in perfect lockstep with when they’re needed. A typical I/O context might look like this:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"data/hello.txt"</span>, <span class="st">'w'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">file</span>.write(<span class="st">"hello"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>PyMC’s approach to modelling seeks to simplify the syntax by requiring that their models be used within the bounds of a context. It looks something like this:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> test_model: </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    testPrior <span class="op">=</span> pm.Normal(<span class="st">"testPrior"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Anytime you want to create a model, add variables to a model, or specify any other aspect of the model or how you plan to fit it, you can do so using PyMC’s context management. In the code block above, we defined a new model and called it <code>test_model</code>. That object now persists in our global namespace, and we can call it directly, which will prompt PyMC to give us a (slightly confusing) printout of the model specification:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>test_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can also examine the individual variables, which also exist in the namespace by themselves:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>testPrior</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, we can also call the model directly with the <code>with</code> statement to add more variables (or do whatever else we please):</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> test_model:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    anotherTest <span class="op">=</span> pm.Normal(<span class="st">"anotherTest"</span>, mu<span class="op">=</span><span class="fl">2.5</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>test_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="specifying-the-model-in-pymc" class="level4" data-number="20.4.1.2">
<h4 data-number="20.4.1.2" class="anchored" data-anchor-id="specifying-the-model-in-pymc"><span class="header-section-number">20.4.1.2</span> Specifying the Model in PyMC</h4>
<p>Now, we can start describing our model. We’re going to do this in chunks, starting with the priors:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> pool_model:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pm.Normal(<span class="st">"alpha"</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, lam<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We used one line per prior to define a distribution for each. The distributions themselves were drawn from PyMC’s library of distributions, which contains all of the distributions we discussed in Chapter 26 and other well-known distributions.</p>
<p>Each call to <code>pm.Normal</code> in the code above included 3 arguments, the first of which is always a string representation of the variable’s name. It’s up to you how you name your variables. If at all possible, I prefer to name them so that they’re a one-to-one match with their Python counterparts. Doing so makes it much easier to read model output without cross-referencing against your model specification. The second and third arguments were passed as keyword arguments (they don’t need to be, but we wanted to make it explicit here); these are the <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> we know and love, and they represent the mean and standard deviation for each of the Normal distributions we used.</p>
<p>There’s only one exception to the pattern above, which comes in the form of the <code>pm.Exponential</code> distribution we used for the standard deviation of the outcome. It still took in a name as its first argument, but we provided a <code>lam</code> argument, which represents the distribution’s ‘rate’ (and, conveniently, is also the inverse of its mean value).</p>
<p>Now, let’s make another call to our model to add the line which represents the linear model – the part that’s responsible for combining all of the observed variables and priors we specified above:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pool_model:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear Model</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> spend_std</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The line we used to specify the linear model should look very familiar to you - it’s nearly a dead ringer for the line we’ve been using in the formal model specification! The major difference is that we used <code>spend_std</code>, rather than <code>spend</code> – the former is the standardized version of the latter, and PyMC almost always prefers standardized variables. At this point, all that remains is to add the likelihood:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pool_model:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    votes <span class="op">=</span> pm.Normal(<span class="st">"votes"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>vote_std)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Our specification of the likelihood should appear as a straightforward representation of what we had built earlier, but with one major addition: <strong>the ‘observed’ parameter</strong>. When we pass data to this parameter, <em>PyMC knows to treat this variable as a likelihood as opposed to a prior</em>. Notice that if we were to remove the <code>observed=vote_std</code> argument, we would be supplying something that’s functionally identical to the priors we added in step 1.</p>
<p>And that’s it! We now have a fully-specified PyMC model! All we need to do to get it to run is to add one more line, which we’ll do in the following major section. But before we do, we’re going to take a brief detour to make sure that our model isn’t totally off-base.</p>
</section>
</section>
<section id="prior-predictive-check" class="level3" data-number="20.4.2">
<h3 data-number="20.4.2" class="anchored" data-anchor-id="prior-predictive-check"><span class="header-section-number">20.4.2</span> Prior Predictive Check</h3>
<p>One of the most oft-repeated criticisms of the Bayesian paradigm is the use of potentially indefensible prior distributions. Yeah, sounds bad. Is it?</p>
<p>I’ve mentioned previously – and, statisticians with far more expertise than I have have demonstrated elsewhere – that most models are simple enough and are conditioned on large enough volumes of data that <em>any</em> combination of priors, regardless of how off-base they are, will be overwhelmed by the likelihood of the evidence, leaving inference more-or-less unaffected. The only really important exception here is an entirely off-base prior that assigns probabilities of 0 to important parts of the parameter space. Hopefully this is some cause for comfort, but the fact that our models are usually ‘safe’ from prior-based bias does <em>not</em> mean that we can become complacent.</p>
<p>One of the rituals we use to stave off complacency is the <strong>Prior Predictive Check</strong>. As we learned in previous chapters, one model’s prior is another model’s posterior; from a mathematical (but <em>not inferential</em>) standpoint, posteriors and priors are largely identical. This is convenient for us, because it means that we can draw samples from our model’s prior distribution much the same way we’d draw samples from any other distribution. In so doing, we can give ourselves a picture of what our model thinks is likely to occur <em>before it has seen any data</em>.</p>
<p>Fortunately, PyMC has built-in functionality for sampling from the prior (which simply draws sample values from the distributions we’ve already defined). We’ll re-use the model context to achieve this and save the results in a new variable:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pool_model:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    prior_predictive <span class="op">=</span> pm.sample_prior_predictive(</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        samples<span class="op">=</span><span class="dv">50</span>, var_names<span class="op">=</span>[<span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>, <span class="st">'votes'</span>], random_seed<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>prior_predictive</code> object that we just created is an <code>arviz.InferenceData</code> object. We can examine the groups available in this object:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>prior_predictive</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can see that it contains the groups: <code>prior</code>, <code>prior_predictive</code>, and <code>observed_data</code>. To access the samples of our priors and simulated observations, we can use the following:</p>
<ul>
<li>Prior samples are in <code>prior_predictive.prior</code></li>
<li>Simulated observations are in <code>prior_predictive.prior_predictive</code></li>
</ul>
<p>For example, we can access the samples of <code>alpha</code> and <code>beta</code> from the prior:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>alpha_samples <span class="op">=</span> prior_predictive.prior[<span class="st">'alpha'</span>].values.flatten()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>beta_samples <span class="op">=</span> prior_predictive.prior[<span class="st">'beta'</span>].values.flatten()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Take some time to flip through the values in the <code>prior_predictive</code> object, and you’ll notice that they’re stored as xarray DataArrays. If you examine <code>alpha_samples.shape</code>, you’ll see that there are 50 samples (the number of samples we asked for). Similarly for <code>beta_samples</code>.</p>
<p>Now that that’s done, we can just plug the parameter samples into a simple reproduction of our linear model.</p>
<p>Results are shown in <a href="#fig-26_02" class="quarto-xref">Figure&nbsp;<span>20.2</span></a>.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>spend_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">20</span>, <span class="dv">20</span>, <span class="dv">50</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.xlim((<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.ylim((<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>alpha_samples <span class="op">=</span> prior_predictive.prior[<span class="st">'alpha'</span>].values.flatten()</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>beta_samples <span class="op">=</span> prior_predictive.prior[<span class="st">'beta'</span>].values.flatten()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>(alpha_samples, beta_samples):</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is the same linear model that appeared in our PyMC definition above</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    vote_sim <span class="op">=</span> a <span class="op">+</span> b <span class="op">*</span> spend_grid </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(spend_grid, vote_sim, c<span class="op">=</span><span class="st">"k"</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.axhspan(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, facecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.axvspan(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, facecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Expenditure differential (standard deviations)"</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Vote differential (standard deviations)"</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/26_02.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_02" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/26_02.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.2: png
</figcaption>
</figure>
</div>
<p>The above plot contains 50 different regression lines drawn from our model’s prior distributions – a quick glance shows that our priors leave a whole lot of room for improvement. Here’s how you can tell: the intersecting grey areas in the plot represent two standard deviations on both of our variables, which means that roughly 95% of our data points will fall somewhere within the darker grey area of overlap. We can see that the majority of the regression lines we sampled from our model cross through the darker grey area from the lower-left to the upper-right, albeit at slightly too sharp an angle. A great many of the lines, though, only barely skim the edges or corners of the box; some fail to cross it altogether. If your model produces one or two highly suspect regression lines, that’s not a cause for concern. When your model produces a great many (as is the case with ours), it might be time to consider making your priors a little more informative.</p>
<p>Take a look at what we can do by tightening our priors a little. The results are shown in <a href="#fig-26_03" class="quarto-xref">Figure&nbsp;<span>20.3</span></a>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> regularized_model:</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pm.Normal(<span class="st">"alpha"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pm.Normal(<span class="st">"beta"</span>, mu<span class="op">=</span><span class="fl">0.5</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.Exponential(<span class="st">"sigma"</span>, lam<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear Model</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> spend_std</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    votes <span class="op">=</span> pm.Normal(<span class="st">"votes"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>vote_std)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    reg_prior_pred <span class="op">=</span> pm.sample_prior_predictive(</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        samples<span class="op">=</span><span class="dv">50</span>, var_names<span class="op">=</span>[<span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>, <span class="st">'votes'</span>], random_seed<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>spend_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">20</span>, <span class="dv">20</span>, <span class="dv">50</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.xlim((<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>plt.ylim((<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>alpha_samples <span class="op">=</span> reg_prior_pred.prior[<span class="st">'alpha'</span>].values.flatten()</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>beta_samples <span class="op">=</span> reg_prior_pred.prior[<span class="st">'beta'</span>].values.flatten()</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> <span class="bu">zip</span>(alpha_samples, beta_samples):</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is the same linear model that appeared in our PyMC definition above</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    vote_sim <span class="op">=</span> a <span class="op">+</span> b <span class="op">*</span> spend_grid </span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(spend_grid, vote_sim, c<span class="op">=</span><span class="st">"k"</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>plt.axhspan(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, facecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>plt.axvspan(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, facecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Expenditure differential (standard deviations)"</span>)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Vote differential (standard deviations)"</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/26_03.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_03" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/26_03.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.3: png
</figcaption>
</figure>
</div>
<p>Based on the above plot, we can see that our new regularized model has a very strong preference for regression lines that hem closely to the origin (0 on both axes), and feature a moderately positive relationship between <code>spend_std</code> and <code>vote_std</code> (most regression lines have a positive slope). There’s still quite a bit of variability in the predictions: owing to their steeper incline, some of the regression lines travel through a limited span of the middle area. Others are more or less flat (predicting no relationship between spending and votes), and our model even permits a few of the lines to reverse the trend entirely and predict that increased spending is correlated with <em>fewer</em> votes received. All said, <em>MUCH better!</em></p>
<p>When selecting priors for a model, I like to use two simple heuristics:</p>
<ol type="1">
<li>Priors shouldn’t make the impossible possible</li>
<li>Priors shouldn’t make the possible impossible</li>
</ol>
<p>The process of setting good priors involves more than simply following these two heuristics of course, but this is a good starting point. Once you’ve gotten the hang of setting priors following basic guidelines, you should feel free to descend into the particulars at your leisure. A good place to start doing so is <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations"><strong>cite</strong> this guide</a> from the developers of another probabilistic programming tool for Bayesian data analysis called STAN.</p>
<p>Now that we’ve created a better model using more sensible priors, we’re going to abandon it and forge ahead using the worse one. <em>Why?</em> I’ve got two didactic reasons:</p>
<ol type="1">
<li>By proceeding with the worse model, we’ll be able to see how even modest amounts of evidence can overwhelm poorly-specified priors with ease.</li>
<li>It won’t happen until next chapter, but we’ll see how models with poorly-specified priors can do ruinous things to more complex models.</li>
</ol>
</section>
<section id="running-our-model" class="level3" data-number="20.4.3">
<h3 data-number="20.4.3" class="anchored" data-anchor-id="running-our-model"><span class="header-section-number">20.4.3</span> Running Our Model</h3>
<p>Our model is ready to run – all we need to do is to add one more line to get it started! This is where we tell PyMC to sample our model and produce a posterior distribution (which, in PyMC-speak, is contained in a ‘trace’ object). By default, PyMC draws 2,000 samples for each of the 4 chains, resulting in a grand total of 8,000 samples. The first 1,000 samples in each chain will be ‘tuning’ samples, used to get our proverbial marble into the right ballpark before we start drawing samples that we’ll incorporate into the posterior. In terms of the skate bowl metaphor from the previous chapter, you can think of each of the different chains as representing a different marble-robot pair. Each of those 4 pairs will repeat the ‘randomly whack the marble’ process 1,000 times, and the result of all of the marble whacks in aggregate will form our posterior. Let’s get a-whackin’!</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pool_model:</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run Sample Traces</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    trace_pool <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If everything’s working correctly, our PyMC model should spit out a collection of preliminary text followed by a progress bar that should fill up in relatively short order. Running this last line of code hasn’t actually done anything to our model proper, but it has produced a ‘trace’ object that contains all the information we need to see how our model performed under sampling. First, let’s use the trace variable to produce a summary (for which we’ll use the <code>arviz</code> package, which is a companion module to the PyMC package, and which facilitates diagnosis and inference). The standard <code>az.summary</code> printout provides an overwhelming amount of data, so we’re going to artificially limit what it shows us for now. We’ll get to the other important variables a little later:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> az.summary(trace_pool, round_to<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>summary[[<span class="st">'mean'</span>, <span class="st">'sd'</span>, <span class="st">'r_hat'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Each of the rows in the dataframe above are dimensions of our posterior distribution and the three columns represent different summary statistics ArviZ has calculated for us. The three statistics we care about right now are the mean, the standard deviation, and the ‘r_hat’ (or <span class="math inline">\(\hat{r}\)</span>) of each dimension.</p>
<p>If you’ve fit and interpreted regression models before, you might find the mean and sd variables familiar: they simply represent the centre and width of the posterior distribution for that particular dimension. In a Frequentist regression, we would be implicitly comparing each of these hypotheses (one for each covariate) to the assumed ‘null hypothesis’ and deciding whether or not to reject the null hypothesis based on the strength of the evidence. You would usually look for a series of little stars to rapidly assess the statistical significance of each alternative hypothesis. Since this is a Bayesian regression, you’ll find no such machinery here: the numbers we’ve printed here are just a summary of the full answer we’ve tasked ourselves with providing, <em>which is always the full shape of the entire posterior distribution</em>. A good Bayesian is obsessed with retaining as much information and uncertainty as possible throughout the modelling process.</p>
<p>If you are not familiar, the r_hat statistic is a purely diagnostic statistic and is not normally interpreted. If all is well with your model, you would expect to see all of the r_hat values to be 1.00, or very close to. Anything higher than that (even 1.02 or greater) is a sign that something has gone wrong in your model.</p>
</section>
<section id="checking-the-traceplot" class="level3" data-number="20.4.4">
<h3 data-number="20.4.4" class="anchored" data-anchor-id="checking-the-traceplot"><span class="header-section-number">20.4.4</span> Checking the Traceplot</h3>
<p>One of the most important steps in any Bayesian regression model involves checking your model’s ‘traces’ to ensure that nothing went awry behind the scenes. ArviZ has some really nice built-in tools for this, shown for our trace pool model in <a href="#fig-26_04" class="quarto-xref">Figure&nbsp;<span>20.4</span></a>.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(trace_pool, var_names<span class="op">=</span>[<span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>], compact<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/26_04.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_04" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/26_04.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.4: png
</figcaption>
</figure>
</div>
<p>Each row in the foregoing grid of plots corresponds to a row in the dataframe summary we produced above. The left column of plots presents you with the shape of the posterior distribution corresponding to one variable in the model (or, equivalently, one dimension of the posterior distribution). The right column of plots shows you the ‘trace’ of the PyMC sampler as it attempted to fit your model. You can think of each line in each traceplot representing a single marble being swatted around a high-dimensional skate bowl, and each row of the figure (there’s one per parameter) is one of those dimensions. This might seem a bit unintuitive at first, but the x-axis in each of the plots on the left represents the exact same thing as the y-axis of their counterpart in the same row on the right! They both represent the parameter’s value: the left is showing you the estimated posterior distribution of the parameter, and the right is showing you how the marbles moved to produce it (the x-axis for each plot on the right is the ‘sample number’; you can think of the marbles as moving from left to right within each plot).</p>
<p>Another thing you might notice is that all of our parameters look normally distributed now; that isn’t much of a surprise for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, but what about <span class="math inline">\(\sigma\)</span>? Since we used the Exponential distribution as its prior, shouldn’t we expect its posterior to be Exponentially distributed, too? Not at all; the only reason we were using the Exponential distribution was to prevent our model from making the mistake of using negative numbers as potential parameter values for our Normal distribution’s <span class="math inline">\(\sigma\)</span> parameter (which is undefined for all numbers below 0). Even if you use a non-normal distribution for a prior, you’ll often find that your posterior distribution for that parameter is Normal. Nothing to worry about.</p>
<p>What you <em>should</em> be worried about is the shape of your traces. There are three things we want to see in a ‘good’ trace:</p>
<ol type="1">
<li><strong>We want to make sure that the algorithm is stationary</strong>, meaning that it has located the area of highest posterior probability and is spending all of its time bouncing around near it. When chains wander around and never settle in one region of the parameter space, it’s a bad sign. To spot a non-stationary trace, look for lines that spend a good amount of time in one part of the posterior and then suddenly switch to another area and stay there for an extended period.</li>
<li><strong>We want to make sure that our samplers are exploring the posterior space rapidly and efficiently</strong>, which is called ‘good mixing’. When a chain is mixing well, it will appear to be darting around from one side of the posterior distribution to the other rapidly. Chains that aren’t mixing well might be stationary in the long run, but take a long time to move back and forth. To spot a poorly-mixed trace, look for lines that slowly and gradually move around (as opposed to the frenetic, zippy movement of the healthy lines we see above).</li>
<li><strong>We want to make sure that each of the various chains we use have converged</strong>, meaning they all spent most of their time in the same region of the posterior; if 3 chains are stationary in one area of the posterior, but the 4th chain is spending all of its time a good distance away, there’s a problem afoot. It’s often easier to spot non-stationary traces on the left-hand side of the trace plot, where it’s easy to notice if one of the traces’ distributions differs significantly from the others. The small amount of wiggliness we see in the <span class="math inline">\(\sigma\)</span> plot above is no big deal at all.</li>
</ol>
<p>The trace plots we’ve produced here are all ideal. Later on, we’ll show you some that are <em>far</em> from ideal. If you can’t wait to find out what bad trace plots look like, you can find lots of detail at this blog post: https://jpreszler.rbind.io/post/2019-09-28-bad-traceplots/. It features a bunch of examples that are more extreme than anything we’re going to see in this book, but is worth taking a look at nonetheless!</p>
<p>Let’s return to those nice-looking distributions on the left-hand side of the diagram again. You might notice that there are a few different lines in each plot – each of the 4 different chains we used to fit our model is separately represented, each with a different line pattern. In fact, those 4 separate lines appear in the trace plots on the right-hand side, too; they’re just much harder to see individually (which is a good thing - that means our marbles were well-behaved).</p>
<p>Since each of the four lines in each of our distribution plots are in broad agreement (they differ slightly, but not even remotely enough to indicate any problems), we can use these distributions to get an accurate idea of where our model thinks the parameter values are most likely to fall.</p>
</section>
<section id="establishing-credible-intervals" class="level3" data-number="20.4.5">
<h3 data-number="20.4.5" class="anchored" data-anchor-id="establishing-credible-intervals"><span class="header-section-number">20.4.5</span> Establishing Credible Intervals</h3>
<p>Now, let’s dig into each of our variables in a bit more detail; we can do so using ArviZ’s <code>plot_posterior</code> function. Our focus will be on something called the ‘<strong>HDI</strong>’, which stands for the ‘<strong>Highest Density Interval</strong>’. The HDI is the closest thing you’re going to see to the Frequentist ‘95% confidence interval’ (or similar) in Bayesian data analysis. Statistically, the HDI represents the shortest possible interval in one dimension of the posterior distribution which contains a predetermined amount of probability. We use the HDI interval to provide us a sense of the area in the distribution that we’re confident (to a predetermined extent) contains the best-fitting parameter value.</p>
<p>It’s up to us to determine how much of the posterior probability we want to appear inside our HDI. In his classic Bayesian text, Richard McElreath <span class="citation" data-cites="mcelreath2020statistical">(<a href="references.html#ref-mcelreath2020statistical" role="doc-biblioref">2020</a>)</span> uses an abundance of cheek when suggesting that Bayesians should employ a prime number for no other reason than the fact that it is prime. He portrays this as a way of subtly jabbing Frequentists for their automatic use of an arbitrarily-set significance threshold of .05, whose progenitor specifically indicated should not be adopted as a default. Hilarious! (Though to be fair, many Frequentists are themselves trying to get other Frequentists to stop doing that.)</p>
<p>We’ll follow in McElreath’s footsteps and use 0.89, but there’s no good reason why we couldn’t use something like 0.83 or 0.79. The default for most ArviZ plots is 94%; having made our point, we’ll leave the HDI intervals at their defaults from here on out. Results are shown in <a href="#fig-26_05" class="quarto-xref">Figure&nbsp;<span>20.5</span></a>.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">1</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(trace_pool,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                  ax<span class="op">=</span>axs,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                  var_names<span class="op">=</span>[<span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>],</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                  hdi_prob<span class="op">=</span><span class="fl">0.89</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/26_05.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_05" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/26_05.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.5: png
</figcaption>
</figure>
</div>
<p>We decided to force PyMC and ArviZ to plot all three posterior distributions (and their HDIs) on the same unified axis so you could directly compare their positions and widths. The black bars under each of the plotted distributions represent the span of our chosen HDI. The numbers that appear to the left and right of the black bar represent the HDI’s upper and lower bounds – this gives us a precise numerical range within which our chosen probability density can be found.</p>
<p>Remember that unlike the Frequentist paradigm, the Bayesian paradigm allows us to apply probability and probabilistic statements to hypotheses. That’s exactly what we’re doing when we create a credible interval! The credible interval represents the region of the posterior probability within which we expect the underlying parameter value to fall, conditional on a predetermined amount of uncertainty. The lower we set our HDI interval, the tighter it becomes, but the less certain of it we are. In our example above, we used an 89% interval; had we set that interval to, say, 79%, it would occupy a smaller proportion of the number line, but we would also have less confidence that the interval contains the ‘true’ parameter value (if such a thing can be said to exist).</p>
<p>The more certain we are of a parameter’s value (as a result of having a posterior distribution with a smaller standard deviation), the more narrow and concentrated our HDI becomes. But even if we had nearly limitless data to feed into our Bayesian machine, we’d never reach perfect certainty about a parameter value, at least not while using a continuous range of hypotheses. If you think back to our probability primer in Chapter 26, this is because our probability density is an integrated value, and the value of any integral on a span of 0 length is 0: thus, the probability of any single hypothesis (such as <span class="math inline">\(\beta = 1\)</span>) will also be 0. We can only ever speak of probability as accumulating within a <em>range</em> of hypotheses.</p>
<p>The HDI is a common and well-understood method of constructing a credible interval. It is not, however, the only means of doing so. We don’t have the time to cover them in detail, but it’s worth weighing the merits of HDI against other techniques for developing a credible interval. Some place more emphasis on ensuring that the credible interval has the same amount of probability on either side of it, ensuring that it is in the ‘middle’ of the posterior distribution. Others mimic the HDI, but allow it to split in the middle so as to cover a 2-humped posterior. Good options abound, many of which can be found in the details of the <a href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_posterior.html">ArviZ’s <code>plot_posterior</code> documentation</a>.</p>
</section>
<section id="posterior-predictive-checks" class="level3" data-number="20.4.6">
<h3 data-number="20.4.6" class="anchored" data-anchor-id="posterior-predictive-checks"><span class="header-section-number">20.4.6</span> Posterior Predictive Checks</h3>
<p>Just in case you hadn’t yet seen enough plots of roughly normal-looking distributions, we’re going to do one more. In much the same way as we drew samples from our model’s prior distribution to perform a prior predictive check, we can draw samples from our model’s posterior distribution to perform a <strong>posterior predictive check</strong>. While the purpose of the prior predictive was to ensure that our model wasn’t out to lunch, the posterior predictive is designed to see how well it performs at <strong>retrodicting</strong> the evidence we fed to it.</p>
<p>Just as with the prior predictive, we start by drawing samples from our model:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pool_model:</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    ppc <span class="op">=</span> pm.sample_posterior_predictive(trace_pool, var_names<span class="op">=</span>[<span class="st">'votes'</span>, <span class="st">'alpha'</span>, <span class="st">'beta'</span>, <span class="st">'sigma'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If you inspect it, you’ll find that the resulting <code>ppc</code> object is an <code>arviz.InferenceData</code> object. We can use this object directly with the <code>ArviZ</code> functions. In the code cell below, we use the <code>az.plot_ppc</code> function to produce a plot of our posterior predictive (<a href="#fig-26_06" class="quarto-xref">Figure&nbsp;<span>20.6</span></a>):</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>az.plot_ppc(ppc, num_pp_samples<span class="op">=</span><span class="dv">100</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/26_06.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_06" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/26_06.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.6: png
</figcaption>
</figure>
</div>
<p>In the above plot, observations from our outcome variable (the standardized vote differential) are arranged along the x-axis, and the frequency (or density) of an observation of that value is tracked along the y-axis. The light wispy lines represent all of the retrodictions made by one set of posterior parameter values (of which we sampled 100); the dashed line represents the overall average of each sample. The solid black line represents the observed data.</p>
<p>Ideally, we’d want to see our model adhere more closely to the observed data: as it stands, our model tends to underpredict the number of congressional districts that the Republicans won by a single standard deviation and greatly overpredicts the number of extremely close races (in and around the origin).</p>
</section>
<section id="plotting-uncertainty" class="level3" data-number="20.4.7">
<h3 data-number="20.4.7" class="anchored" data-anchor-id="plotting-uncertainty"><span class="header-section-number">20.4.7</span> Plotting Uncertainty</h3>
<p>I know I’ve said it quite a lot already, but one of the reasons why we use Bayesian methods in the first place is because we want to preserve uncertainty to the greatest extent possible throughout the entire modelling process. You’ll often find that other approaches to regression analysis produce a ‘line of best fit’ or a ‘predictor line’ or something similar. In Bayesian analysis, we instead produce a <em>range</em> of such lines, each of which is probabilistically drawn from our posterior distribution, and each of which differs from the others. Since it’s difficult to appreciate information at this scale directly, Bayesian regression leans heavily on visualization techniques to provide intuitive guides to inference. Here, we’re going to draw samples of predicted outcomes and parameter values from our posterior distribution (using a PyMC function designed for just such a task), feed those sampled values through our linear model, and plot the 94% HDI range of the results (<a href="#fig-26_07" class="quarto-xref">Figure&nbsp;<span>20.7</span></a>).</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plot_2020_election_fit(spend_std, vote_std, trace_pool, ppc)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'figures/26_07.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-26_07" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-26_07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/26_07.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-26_07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.7: png
</figcaption>
</figure>
</div>
<p>In the above plot, the black line represents the mean (or average) predictor line. Its value was produced by averaging over thousands of such lines, 94% of which fall entirely within the smaller, darker band around the black line; that band represents our model’s uncertainty in the regressor. Our model <em>also</em> models predictive uncertainty – or, in simpler terms, the width of the band within which it expects 94% of the data to fall (which is controlled by our model’s <code>sigma</code> parameter, which we also have some uncertainty about). It’s uncertainty piled upon uncertainty (and so on <em>ad infinitum</em>), but it produces a set of results and visualizations that are remarkably intuitive to read and interpret.</p>
<p>Nevertheless, we can now produce a preliminary interpretation of what our model is telling us: using the posterior predictive plot and the various parameters summaries from earlier, our model is indicating an increase of 1 standard deviation in spending differential tends to correlate with a roughly 0.45 standard deviation increase in vote differential.</p>
<p>There’s just one catch, which you may or may not have noticed by looking at the plot. This model sucks. We can do better. That’s what the next chapter is all about.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="20.5">
<h2 data-number="20.5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">20.5</span> CONCLUSION</h2>
<section id="key-points" class="level3" data-number="20.5.1">
<h3 data-number="20.5.1" class="anchored" data-anchor-id="key-points"><span class="header-section-number">20.5.1</span> Key Points</h3>
<ul>
<li>Bayesian regression is a powerful, flexible approach to regression analysis</li>
<li>Just because simple Bayesian regression models with plenty of data aren’t all that sensitive to the priors placed on their latent variables doesn’t mean that you should be complacent about setting priors: a prior predictive check can be helpful in this regard</li>
<li>Bayesian regression emphasizes preserving and visualizing uncertainty whenever and however possible</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-martin2018bayesian" class="csl-entry" role="listitem">
Martin, Osvaldo. 2018. <em>Bayesian Analysis with Python: Introduction to Statistical Modeling and Probabilistic Programming Using Pymc and ArviZ</em>. Packt Publishing Ltd.
</div>
<div id="ref-mcelreath2020statistical" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical Rethinking: A Bayesian Course with Examples in r and Stan</em>. CRC press.
</div>
<div id="ref-salvatier2016probabilistic" class="csl-entry" role="listitem">
Salvatier, John, Thomas Wiecki, and Christopher Fonnesbeck. 2016. <span>“Probabilistic Programming in Python Using Pymc.”</span> <em>PeerJ Computer Science</em> 2: e55.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./19-causality.html" class="pagination-link" aria-label="Causality">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Causality</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./21-multilevel-regression-with-post-stratification.html" class="pagination-link" aria-label="Multilevel regression with post-stratification">
        <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multilevel regression with post-stratification</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/UWNETLAB/dcss_supplementary/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>