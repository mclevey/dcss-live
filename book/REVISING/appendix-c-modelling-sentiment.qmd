# Modelling Sentiment


In this tutorial, we'll explore various approaches to modeling sentiment in text data. We'll start with simple dictionary-based methods for sentiment analysis, which rely on predefined lists of positive and negative words. While these methods are easy to understand and implement, they come with significant limitations. Next, we'll explore a more sophisticated approach using the VADER (Valence Aware Dictionary and Sentiment Reasoner) model, which combines dictionary-based methods with rules to improve accuracy. Third, we'll dive into transformer-based models, the state-of-the-art in sentiment analysis, which leverage deep learning to understand context and nuance in text data.

You can think of the evolution of approaches in this tutorial in the same general terms as the three waves of topic models I introduced in the previous tutorial.

By the end of this tutorial, you will have a solid understanding of four different approaches to sentiment analysis, their strengths and weaknesses, and how to implement them in Python.

## Learning Objectives

By the end of this tutorial, you should be able to:

1. Compare Approaches to Sentiment Analysis
    - Describe the differences between dictionary-based, rule-based, and transformer-based methods for sentiment analysis.
    - Explain the advantages and limitations of each approach.
2. Implement Sentiment Analysis
    - Use dictionary-based methods to calculate sentiment scores.
    - Apply VADER sentiment analysis, which combines dictionary and rule-based methods.
    - Implement transformer-based sentiment analysis using state-of-the-art models like RoBERTa.
3. Visualize and Interpret Sentiment Scores
    - Create histograms and bar charts to visualize sentiment distributions.
    - Compare the results of different sentiment analysis methods.

# Setup

```python
import pandas as pd
import spacy
import requests
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

nlp = spacy.load("en_core_web_sm")
```


Let's load the dataset and inspect its structure.

```python
comments = pd.read_csv('output/comments.csv')
comments.info()
```

Let's take a sample to work a little faster. You can always remove this line and re-run the code later.

```python
comments = comments.sample(1_000)
comments.head()
```

# The First Approach: Dictionary Methods

Dictionary-based sentiment analysis is a straightforward method that involves counting the number of positive and negative words in a text. While easy to implement, this approach often struggles with context, polysemy, and sarcasm, and may not accurately represent capture sentiment in text data.

We'll start by loading lists of positive and negative words from the *Computational Analysis of Communication* book using the requests package. Next, we'll combine these lists into a single dataframe representing our sentiment dictionary.

```python
poswords_url = "https://cssbook.net/d/positive.txt"
negwords_url = "https://cssbook.net/d/negative.txt"

def load_word_list(url):
    response = requests.get(url)
    words = response.text.splitlines()
    return words

positive_words = load_word_list(poswords_url)
negative_words = load_word_list(negwords_url)

positive_df = pd.DataFrame({'word': positive_words, 'value': 1})
negative_df = pd.DataFrame({'word': negative_words, 'value': -1})

sent_dict = pd.concat([positive_df, negative_df], ignore_index=True)
print(sent_dict.sample(30))
```


## Tokenization and Sentiment Scoring

We'll define a simple function to tokenize the text using SpaCy, which helps us break down each comment into individual words.

We'll define a simple function to tokenize the text with spacy.

```python
def spacy_tokenizer(text):
    if isinstance(text, str):
        doc = nlp(text.lower())
        return [token.text for token in doc]
    else:
        return []

comments['word'] = comments['text'].apply(spacy_tokenizer)
```

Let's take a quick look.

```python
comments['word'].sample(30)
```

Now, we'll process the data further by exploding the words into individual rows, allowing us to join them with our sentiment dictionary and calculate sentiment scores.

```python
comments_exploded = comments.explode('word')
df_joined = comments_exploded.merge(sent_dict, on='word', how='inner')
df_joined
```

## Aggregating Sentiment Scores

We'll group the data by comment_id to calculate the overall sentiment score for each comment by summing the individual word sentiment scores.

```python
df_scores = df_joined.groupby('comment_id').agg(
    senti_score=pd.NamedAgg(column='value', aggfunc='sum'),
    text=pd.NamedAgg(column='text', aggfunc='first')
).reset_index()

df_scores.head()
```

## Visualizing Dictionary-Based Sentiment

Let's visualize the distribution of sentiment scores using a humble histogram.

```python
ax = df_scores['senti_score'].plot(
  kind='hist', bins=20, color="black", alpha=0.7, edgecolor='black', figsize=(10, 6)
)

ax.yaxis.set_major_formatter(ticker.FuncFormatter(
  lambda x, pos: f'{int(x):,}')
)

plt.title('Dictionary-based Sentiment Counts\n', loc="left")
plt.xlabel('\n' + r'$\longleftarrow$ more negative | more positive $\longrightarrow$')
plt.ylabel('Frequency\n')
plt.show()
```

Let's try another approach. This time, one that combines a dictionary approach with a rules=based approach. You can think of this as a refinment of a model based on model criticism in an iterative modelling loop.

# The Second Approach: VADER (Dictionaries + Rules)

VADER (Valence Aware Dictionary and sEntiment Reasoner) is a more sophisticated sentiment analysis tool that combines a dictionary-based approach with a rule-based method to better capture context, negation, and intensifiers in text. We'll start by importing VADER and initializing the `SentimentIntensityAnalyzer`.

```python
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()
```

## Computing Sentiment Scores with VADER

We’ll define a function that uses VADER’s `.polarity_scores()` method to compute a compound sentiment score for each comment.

```python
def vader_sentiment(text, analyzer):
    if isinstance(text, str):
        scores = analyzer.polarity_scores(text)
        return scores['compound']
    else:
        return None

comments['vader_score'] = comments['text'].apply(lambda x: vader_sentiment(x, analyzer))
comments[['text', 'vader_score']].head()
```

## Visualizing VADER Sentiment

Now, let's visualize the VADER sentiment scores using a histogram. We'll use Pandas `plot()` method, which just calls matplotlib.

```python
ax = comments['vader_score'].plot(
  kind='hist', bins=20, color="black", alpha=0.7, edgecolor='black', figsize=(10, 6)
)

ax.yaxis.set_major_formatter(ticker.FuncFormatter(
  lambda x, pos: f'{int(x):,}')
)

plt.title('Compound VADER Sentiment Scores\n', loc="left")
plt.xlabel('\nCompound Sentiment')
plt.ylabel('Frequency\n')
plt.show()
```


## Comparison of Dictionary and VADER Sentiment Analysis

Let's compare the results of our two sentiment analysis methods by plotting their histograms side by side. When you interpret these plots, remember that the x-axes are quite different.

```python
import matplotlib.pyplot as plt

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))

ax1.hist(df_scores['senti_score'], bins=20, color="blue", alpha=0.5, edgecolor='black')
ax1.set_title('(a) Dictionary counts\n', loc='left')
ax1.set_xlabel('\nCounts')
ax1.set_ylabel('Frequency\n')
ax1.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x):,}'))

ax2.hist(comments['vader_score'], bins=20, color="red", alpha=0.5, edgecolor='black')
ax2.set_title('\n(b) Dictionaries + Rules via VADER\n', loc='left')
ax2.set_xlabel('\nVADER Compound Sentiment Score')
ax2.set_ylabel('Frequency\n')
ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x):,}'))

# Adjust the layout
plt.tight_layout()
plt.show()
```

We can't say from this plot, but if you spend some time looking at examples, you'll see VADER's rule-based adjustments do provide some improvements over the simple dictionary approach.

# The Third Approach: Transformer-Based Sentiment Analysis

As we learned in the last tutorial and video lectures, transformer models, like those based on the BERT architecture, have revolutionized natural language processing in general, including sentiment analysis. They capturing deep contextual information and do a much better job of "understanding" the nuances of language. We'll use a pre-trained transformer model to analyze sentiment in our comments, which is very common.^[You can fine-tune these to your specific use case, but that is beyond the scope of this course.] We'll start by specifying the model we’ll use, which is designed for sentiment analysis on social media text.

```python
model = "cardiffnlp/twitter-roberta-base-sentiment-latest"
```

## Applying the Transformer Model

We'll use the `label_sentiment()` function from the course package to apply the sentiment model to our dataset.

::: { .callout-note }
Note that the code below will take a while to run. Progress bars will give you a sense of how long to expect.
:::

```python
import src.text as t

sentiment = t.label_sentiment(
    model=model, df=comments, textcol="text", idcol="comment_id"
)

sentiment
```

## Analyzing Sentiment Scores

Next, we’ll determine the dominant sentiment (positive, neutral, or negative) for each comment based on the highest probability score.

```python
sentiment['dominant_sentiment'] = sentiment[['sentiment_negative', 'sentiment_neutral', 'sentiment_positive']].idxmax(axis=1)

sentiment[['sentiment_negative', 'sentiment_neutral', 'sentiment_positive', 'dominant_sentiment']].head()
```

Let's plot a comparison. We could do this as a bar graph (or whatever), but I prefer to do it this way:

```python
from src.networks import plot_line_comparison

for_plotting = sentiment_counts.to_dict()

plot_line_comparison(
    for_plotting,
    xrange=(315, 350),
    print_decimals=False,
    title="",
    xlabel='\nFrequency of dominant sentiment scores in the talksatgoogle YouTube Data',
    filename="output/yt_sentiment_comparison.png"
)
```


We can also look at the distribution of sentiment scores, not just the dominant ones.

```python
sentiment[['sentiment_negative', 'sentiment_neutral', 'sentiment_positive']].plot(
    kind='hist', bins=50, alpha=0.7, edgecolor='black', figsize=(10, 6), subplots=True
)
plt.suptitle('Distribution of Sentiment Scores')
plt.show()
```

# Conclusion

It’s important to understand both the traditional and modern approaches to effectively apply them in your research, especially as transformer-based models become more common. In this tutorial notebook, we explored three different approaches to sentiment analysis: dictionary-based methods, VADER (which combines dictionary and rule-based approaches), and transformer-based models. Each method has its own strengths and weaknesses, and the choice of method should be guided by the specific requirements of your analysis.