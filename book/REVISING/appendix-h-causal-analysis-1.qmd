# Causal Inference with Observational Data: Part 1

## Introduction

This tutorial introduces causal inference with observational data, following the framework developed by Judea Pearl and extended by researchers in the field of causal inference and Bayesian data analysis. Our approach in this tutorial is heavily inspired by Richard McElreath's *Statistical Rethinking* (2nd edition). McElreath's approach combines the power of **graphical models** for causal reasoning with the flexibility of **Bayesian inference**, providing a robust framework for understanding and estimating causal effects.

In what follows, we'll work through a simple example to illustrate causal analysis. I'll demonstrate how to:

- construct and interpret causal graphical models,
- translate these graphical models into probabilistic models,
- perform causal inference by simulating interventions, and
- estimate causal effects using Bayesian inference

By the end of this tutorial, you'll have a solid foundation in causal inference with observational data, and you'll be able to apply these concepts to more complex real-world scenarios. We will build on this foundation in later tutorials.

### Causal Inference with PyMC

The approach to causal inference introduced here, which combines graphical models with Bayesian inference, offers several key advantages:

- **Explicit representation of causal assumptions**: Graphical models allow us to clearly articulate our assumptions about the causal relationships between variables.
- **Flexibility in model specification**: The Bayesian framework allows us to incorporate prior knowledge and uncertainty into our models.
- **Ability to reason about interventions**: By manipulating our graphical and probabilistic models, we can simulate interventions and estimate their effects.
- **Quantification of uncertainty**: Bayesian inference provides full posterior distributions, allowing us to quantify our uncertainty about causal effects.

To make this more concrete, let's walk through a very simple example involving rain, sprinklers, and wet grass. It may not be the most exciting example, but it illustrates key concepts in causal inference and helps build a conceptual foundation for more complex and interesting analyses. We'll begin by developing a graphical model representation of our causal assumptions.

### Graphical Models

Graphical models are a simple but powerful way of representing causal relationships between variables. They enable us to encode our assumptions about how different factors influence each other in a simple visual and intuitive way. In this example, we're goping to consider the relationships between three variables:

- Rain (**R**),
- Sprinkler (**S**), and
- Wet Grass (**W**)

We believe that these variables are causally related in that (1) rain **R** affects whether the Sprinkler **S** is on, and (2) both Rain **R** and Sprinkler **S** affect whether the Grass **G** is Wet **W**. We can represent this causal model graphically as follows:

```{dot}
digraph G {
    rankdir=TB;
    node [shape=circle];
    
    // Original model
    subgraph cluster_0 {
        label = "Original Model";
        R [label="R\n(Rain)"];
        S [label="S\n(Sprinkler)"];
        W [label="W\n(Wet Grass)"];
        
        R -> S;
        R -> W;
        S -> W;
    }
    
    // Model with DO(S=1) intervention
    subgraph cluster_1 {
        label = "Model with DO(S=1)";
        R2 [label="R\n(Rain)"];
        S2 [label="S=1\n(Sprinkler On)", shape=box];
        W2 [label="W\n(Wet Grass)"];
        
        R2 -> W2;
        S2 -> W2;
    }
}
```


In this graphical model, nodes (circles) represent variables in our system and arrows represent direct causal relationships between variables. The direction of the arrow indicates the direction of causality. In this case, the arrow from **R** to **S** indicates that Rain causally influences the Sprinkler state. The arrows from both **R** and **S** to **W** indicate that both Rain and Sprinkler causally influence whether the Grass is Wet. Altogether, the graphical model represents our causal assumptions about the problem at hand. It tells us, for example, that *if we were to **intervene** and turn the sprinkler on or off*, it would affect the wetness of the grass, but it wouldn't affect whether it's raining. 

The right side of the graph shows what happens when we apply the DO-operator, written as DO(S=1). This represents an intervention where we forcibly set the Sprinkler to be on, regardless of whether it's raining. In this intervened model:

- The node for S becomes a square, indicating it's been set to a fixed value.
- The arrow from R to S is removed, as rain no longer influences the sprinkler state.

This illustrates a key concept in causal inference: when we intervene on a variable, we break its dependence on its usual causes.

## Graphical Models + Bayesian Data Analysis

We can clearly represent our assumptions about causal relationships by encoding them in the structure of a graphical model, but graphical models themselves can't make predictions or inferences; they are purely conceptual tools. The next step is to use them to inform the development of Bayesian models. This combination of graphical models and Bayesian inference allows us to:

- explicitly encode our causal assumptions (through the structure of the graphical model),
- incorporate uncertainty and prior knowledge (through prior distributions in the Bayesian model),
- update our beliefs based on observed data (through Bayesian inference), and 
- reason about interventions and their effects (by manipulating the model structure).

The Bayesian approach is particularly well-suited to causal inference because it provides a natural way to incorporate uncertainty at all levels of the model. It provides full posterior distributions, giving us a nuanced view of possible causal effects, and allows us to work with large and small samples, as well as simple and complex models. 

## Developing a Bayesian Model Based on Our Graphical Model Using PyMC

As previously mentioned, we can use our graphical model as a foundation for developing a Bayesian probabilistic model. To do so, we'll specify probability distributions for each variable in our model, taking into account the causal relationships we've defined We'll do all of this using the Python package PyMC.

In what follows, we'll:

- define the structure of our model in PyMC,
- specify prior distributions for our parameters, 
- define the relationships between variables, and 
- sample from the posterior distribution of our model.

This process allows us to move from a conceptual causal model to a computational model that we can use for inference and prediction.
Let's start by importing the necessary libraries and setting a random seed for reproducibility:

```python
import pymc as pm
import numpy as np
import arviz as az

np.random.seed(36)
```

Now, let's define our model:

```python
with pm.Model() as sprinkler_model:
    # Rain variable (0: No rain, 1: Rain)
    rain = pm.Bernoulli('R', p=0.2)
    
    # Sprinkler variable (0: Off, 1: On)
    # We use pm.Data() to allow for intervention
    sprinkler = pm.Data('S', np.array([0, 1]))  # Possible values for sprinkler
    sprinkler_prob = pm.Deterministic('S_prob', pm.math.switch(rain, 0.01, 0.4))
    sprinkler_on = pm.Bernoulli('S_on', p=sprinkler_prob, observed=sprinkler)
    
    # Wet grass variable (0: Dry, 1: Wet)
    # Wet if either raining or sprinkler is on
    grass_wet = pm.Bernoulli('W', p=pm.math.switch(rain | sprinkler_on, 0.99, 0.01))
```

This model structure directly reflects the causal relationships we specified in our graphical model. Let's break it down.

- Rain (**R**): We model rain as a Bernoulli variable with a probability of 0.2. This means there's a 20% chance of rain on any given day. This is an arbitrary choice for the purposes of illustration. 
- Sprinkler (**S**): The sprinkler's behavior depends on whether it's raining. We use a switch statement to set different probabilities:
    - If it's raining (rain = 1), the probability of the sprinkler being on is 0.01 (1%)
    - If it's not raining (rain = 0), the probability is 0.4 (40%)
- Wet Grass (**W**): The probability of the grass being wet depends on both rain and the sprinkler. We set a high probability (0.99) if either it's raining or the sprinkler is on, and a low probability (0.01) otherwise.

Now that we've defined our model, let's sample from it to generate posterior distributions for our variables:

```python
with sprinkler_model:
    # Use NUTS sampler for efficient sampling
    trace = pm.sample(1000, return_inferencedata=True)
```

The `trace` object contains samples from the posterior distribution of our model. These samples represent our updated beliefs about the model parameters after observing the data.

Let's examine the results:

```python
print("Original Model Results:")
print(az.summary(trace, var_names=['R', 'S_prob', 'W']))
```

This summary provides key statistics for each variable in our model:

- **R**: The posterior probability of rain
- **S_prob**: The probability of the sprinkler being on, which depends on whether it's raining
- **W**: The probability of the grass being wet

To calculate the overall probability of wet grass, we can take the mean of our samples:

```python
p_wet = trace.posterior['W'].mean().item()
print(f"Probability of wet grass: {p_wet:.3f}")
```

This probability -- `python p_wet` -- represents our model's prediction of how often the grass will be wet, taking into account both rain and the sprinkler system. However, this is not yet a causal estimate! To perform a **causal** analysis with this model, we need to **simulate interventions**. Let's do that now.

## Causal Inference with an Intervention

Causal models is enable us to reason about **interventions**, which in this case refers to actions that force a variable to take a specific value, regardless of its usual causes. In our sprinkler example, we might want to know: "What would happen to the probability of wet grass if the sprinkler is always turned on?"

This kind of question is focused on the causal effect of an action, which goes well beyond computing predictions. One way of doing this is by using a DO-operator (cite Pearl). In our case, we would write DO(S=1) to indicate that the sprinkler is always turned on.

To simulate this intervention with PyMC, we need to modify our `sprinkler_model` to always set the sprinkler to "on" and remove the influence of rain on the sprinkler (as shown in our intervened graphical model). Then we can sample from the modified model and calculate a causal estimate. It looks like this: 

```python
with sprinkler_model:
    # create a new model context where the sprinkler is always on
    pm.set_data({"S": np.ones_like(sprinkler.eval())})

    trace_intervened = pm.sample(1000, return_inferencedata=True)
```

In the code above, we used `pm.set_data()` to force the sprinkler to always be on. This automatically breaks the connection between rain and the sprinkler -- which is what we want --  because we're directly setting the sprinkler state. Let's examine the results of this intervention!

```python
print("\nIntervened Model Results (Sprinkler always on):")
print(az.summary(trace_intervened, var_names=['R', 'W']))
```

And now we can calculate the probability of wet grass given the intervention. In other words, it's the probability of wet grass if we always turned the sprinkler on, regardless of whether it's raining.

```python
# Calculate probability of wet grass with sprinkler always on
p_wet_intervened = trace_intervened.posterior['W'].mean().item()
print(f"Probability of wet grass with sprinkler always on: {p_wet_intervened:.3f}")
```

Finally, we can calculate the causal effect of our intervention.

```python
causal_effect = p_wet_intervened - p_wet
print(f"\nCausal effect of turning sprinkler on: {causal_effect:.3f}")
```

Great! But what does a causal effect of `python causal_effect` mean? 

The causal effect we've calculated here represents the change in the probability of wet grass caused by always turning the sprinkler on. A positive value indicates that turning the sprinkler on increases the chance of wet grass, and a negative value indicates a decrease.

## Interpretation and Conclusion

The causal effect we calculated in this introductory tutorial tells us how much the probability of wet grass changes when we intervene to always turn the sprinkler on. This goes well beyond mere correlation to tells us something about the consequences of an action. 

There are a few key things to note here. First, the causal effect is different from the simple conditional probability $P(W|S=1)$, which includes cases where the sprinkler is on because it's not raining. Our causal effect, on the other hand, considers what would happen if we forced the sprinkler on regardless of rain. Second, our model allows us to separate the direct effect of the sprinkler from the confounding effect of rain. This is crucial for understanding the true impact of our intervention -- turning the sprikler on. Finally, the Bayesian approach gives us not just a point estimate, but a full distribution of possible causal effects. This allows us to quantify our uncertainty about the effect.

This tutorial has introduced you to the basics of causal inference using graphical models and Bayesian analysis with PyMC. With this simple foundation, you can begin to explore more complex problems and models. Just remember, as McElreath (2020) emphasizes in *Statistical Rethinking*," the real power of this approach comes from careful thinking about causal relationships, not the mathematics and computations. Always consider your causal assumptions carefully, and revise your models iteratively as you learn.